{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05057ffd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fdaf5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load fMRI data\n",
    "mat_nb = scipy.io.loadmat('E:/Brain_Develop_Knock/KARIM and ME/nback_fmri_power264.mat')\n",
    "fmri_data = mat_nb.get('nback_fmri_power264')[0]\n",
    "\n",
    "# Load phenotype data\n",
    "pheno_data = pd.read_excel('E:/Brain_Develop_Knock/KARIM and ME/upenn_meta_cnb.xlsx')\n",
    "subj_id_pheno = pheno_data['subject id']\n",
    "\n",
    "# Load p264 template\n",
    "p264_template = pd.read_excel('E:/Brain_Develop_Knock/KARIM and ME/PP264_template_subnet.xls', header=0)\n",
    "\n",
    "# Initialize a list to store correlation features for each subnetwork\n",
    "correlation_features_per_subnet = []\n",
    "\n",
    "# Initialize lists to store correlation features for each subnet and age\n",
    "correlation_features_per_subnet = [[] for _ in range(14)]  # Initialize a list for each subnet\n",
    "age_in_month_subnet = []  # Initialize age_in_month_subnet as a list\n",
    "\n",
    "# Iterate through subjects\n",
    "for subj_count in range(len(mat_nb.get('nback_fmri_power264')[0])):\n",
    "    print(f\"SUBJ_COUNT is: {subj_count}\")\n",
    "\n",
    "    subj_id_nb = fmri_data[subj_count][0][0][0][0][0]\n",
    "\n",
    "    # Check if subject is present in pheno_data\n",
    "    if subj_id_nb in subj_id_pheno.values:\n",
    "        # Get age of the subject in months\n",
    "        subj_age_in_month = np.array(mat_nb.get('nback_fmri_power264')[0][subj_count][0][0][0][1])\n",
    "\n",
    "        # Extract bold signals for all 264 regions\n",
    "        bold_signals_all_regions = fmri_data[subj_count][2]\n",
    "\n",
    "        # Compute Pearson correlation for all regions without transposing\n",
    "        correlation_matrix_all_regions = np.corrcoef(bold_signals_all_regions)\n",
    "\n",
    "        # Iterate through subnetwork columns\n",
    "        for subnet_count in range(1, 15):\n",
    "            # Get subnet indices from p264_template\n",
    "            subnet_inds = p264_template[p264_template['subnet_inds'] == subnet_count]['Original_ROI'].values - 1\n",
    "\n",
    "            print(f\"subj_count: {subj_count}, subnet_count: {subnet_count}, subnet_inds: {subnet_inds}\")\n",
    "\n",
    "            # Extract values before the diagonal element for the current subnet\n",
    "            values_before_diagonal = [\n",
    "                correlation_matrix_all_regions[i, subnet_col] for subnet_col in subnet_inds for i in range(subnet_col)\n",
    "            ]\n",
    "\n",
    "            print(f\"Shape of values_before_diagonal: {len(values_before_diagonal)}\")\n",
    "\n",
    "            # Append the list for the current subnet with values_before_diagonal\n",
    "            correlation_features_per_subnet[subnet_count - 1].append(values_before_diagonal)\n",
    "\n",
    "            print(f\"Shape of correlation_features_per_subnet {subnet_count}: {np.array(correlation_features_per_subnet[subnet_count - 1]).shape}\")\n",
    "\n",
    "        # Store age in months for the current subject\n",
    "        age_in_month_subnet.append(subj_age_in_month)\n",
    "\n",
    "# Convert the lists of lists to a list of 2D NumPy arrays for further analysis\n",
    "correlation_features_per_subnet = [np.array(features) for features in correlation_features_per_subnet]\n",
    "age_in_month_subnet = np.array(age_in_month_subnet)\n",
    "\n",
    "# Print shapes\n",
    "for i, features in enumerate(correlation_features_per_subnet, start=1):\n",
    "    print(f\"Shape of correlation_features_per_subnet{i}: {features.shape}\")\n",
    "\n",
    "print(f\"Shape of age_in_month_subnet: {age_in_month_subnet.shape}\")\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Extracting the ages from the 3D array\n",
    "ages = y[:, :, 0]\n",
    "\n",
    "# Creating y_cls based on the age threshold of 13 years\n",
    "y_cls = np.where(ages > 14* 12, 1, 0)\n",
    "\n",
    "# Counting the number of rows with y_cls = 1 and y_cls = 0\n",
    "count_y_cls_1 = np.count_nonzero(y_cls == 1)\n",
    "count_y_cls_0 = np.count_nonzero(y_cls == 0)\n",
    "\n",
    "# Print the counts\n",
    "print(\"Number of rows with y_cls = 1:\", count_y_cls_1)\n",
    "print(\"Number of rows with y_cls = 0:\", count_y_cls_0)\n",
    "\n",
    "\n",
    "\n",
    "# Function to normalize a group\n",
    "def normalize_group(group):\n",
    "    min_val = np.min(group, axis=0)\n",
    "    max_val = np.max(group, axis=0)\n",
    "    normalized_group = (group - min_val) / (max_val - min_val)\n",
    "    return normalized_group\n",
    "\n",
    "# Normalize each group and store in X_subnet_norm\n",
    "X_subnet_norm = [normalize_group(group) for group in X_subnet]\n",
    "\n",
    "# Print the shape of the first normalized group as an example\n",
    "print(\"Shape of the first normalized group:\", X_subnet_norm[0].shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from keras.layers import Input, Dense, Concatenate\n",
    "from keras.models import Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Extract the number of subjects\n",
    "num_subjects = correlation_features_per_subnet[0].shape[0]\n",
    "\n",
    "# Convert correlation_features_per_subnet to include a third dimension (batch_size, input_dim)\n",
    "X_subnet = [subnet.reshape((num_subjects, -1, 1)) for subnet in correlation_features_per_subnet]\n",
    "\n",
    "# Define the input layers for each subnet\n",
    "subnet_inputs = []\n",
    "\n",
    "num_features_list = [1008, 215, 735, 858, 5994, 754, 4867, 4693, 3789, 2951, 2037, 2832, 974, 3009]\n",
    "\n",
    "for i, num_features in enumerate(num_features_list):\n",
    "    subnet_input = Input(shape=(num_features,), name=f'input_subnet_{i + 1}')\n",
    "    subnet_inputs.append(subnet_input)\n",
    "\n",
    "# Dense layers for each subnet\n",
    "subnet_dense_layers = [Dense(24, activation='elu')(subnet_input) for subnet_input in subnet_inputs]\n",
    "\n",
    "# Concatenate the output of each subnet\n",
    "concatenated_layer = Concatenate()(subnet_dense_layers)\n",
    "\n",
    "# Dense layer with 32 neurons\n",
    "dense_layer_32 = Dense(32, activation='elu')(concatenated_layer)\n",
    "\n",
    "# Dense layer with 32 neurons\n",
    "dense_layer_32 = Dense(64, activation='elu')(dense_layer_32)\n",
    "\n",
    "# Dense layer with 32 neurons\n",
    "dense_layer_32 = Dense(128, activation='elu')(dense_layer_32)\n",
    "\n",
    "# Dense layer with 32 neurons\n",
    "#dense_layer_32 = Dense(256, activation='relu')(dense_layer_32)\n",
    "\n",
    "\n",
    "# Dense layer with 32 neurons\n",
    "dense_layer_32 = Dense(256, activation='elu')(dense_layer_32)\n",
    "\n",
    "# Output layer\n",
    "output_layer = Dense(units=1, activation='sigmoid')(dense_layer_32)\n",
    "\n",
    "# Create the model\n",
    "model = Model(inputs=subnet_inputs, outputs=output_layer)\n",
    "\n",
    "\n",
    "from keras.optimizers import Adam\n",
    "from keras.metrics import BinaryAccuracy\n",
    "from keras.losses import BinaryCrossentropy\n",
    "\n",
    "# Assuming you have a binary classification problem\n",
    "\n",
    "# Set the learning rate\n",
    "learning_rate = 0.0001\n",
    "\n",
    "# Set the gradient clipping value\n",
    "clip_value = 0.5\n",
    "\n",
    "# Create the Adam optimizer with learning rate\n",
    "adam_optimizer = Adam(learning_rate=learning_rate, clipvalue=clip_value)\n",
    "\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=adam_optimizer, loss='binary_crossentropy', metrics = 'accuracy')\n",
    "\n",
    "# Display the model summary\n",
    "model.summary()\n",
    "\n",
    "\n",
    "num_epochs = 30\n",
    "batch_size = 128\n",
    "\n",
    "# Train the model with your data\n",
    "model.fit(X_subnet_norm, np.array(y_cls), epochs=num_epochs, batch_size=batch_size, validation_split=0.1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6de1e36",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
