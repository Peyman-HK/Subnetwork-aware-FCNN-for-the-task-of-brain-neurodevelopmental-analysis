{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05057ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load fMRI data\n",
    "mat_nb = scipy.io.loadmat('E:/Brain_Develop_Knock/KARIM and ME/nback_fmri_power264.mat')\n",
    "fmri_data = mat_nb.get('nback_fmri_power264')[0]\n",
    "\n",
    "# Load phenotype data\n",
    "pheno_data = pd.read_excel('E:/Brain_Develop_Knock/KARIM and ME/upenn_meta_cnb.xlsx')\n",
    "subj_id_pheno = pheno_data['subject id']\n",
    "\n",
    "# Load p264 template\n",
    "p264_template = pd.read_excel('E:/Brain_Develop_Knock/KARIM and ME/PP264_template_subnet.xls', header=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9cbf3369",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a list to store correlation features for each subnetwork\n",
    "correlation_features_per_subnet = []\n",
    "\n",
    "# Initialize lists to store correlation features for each subnet and age\n",
    "correlation_features_per_subnet = [[] for _ in range(14)]  # Initialize a list for each subnet\n",
    "age_in_month_subnet = []  # Initialize age_in_month_subnet as a list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e7a1c781",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(mat_nb.get('nback_fmri_power264')[0])\n",
    "subj_count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "13ebd0b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUBJ_COUNT is: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([6.00009963e+11])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"SUBJ_COUNT is: {subj_count}\")\n",
    "\n",
    "subj_id_nb = fmri_data[subj_count][0][0][0][0][0]\n",
    "subj_id_nb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a87bcc33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subj_age_in_month [[116]]\n",
      "bold_signals_all_regions (264, 231)\n",
      "correlation_matrix_all_regions (264, 264)\n"
     ]
    }
   ],
   "source": [
    "# Check if subject is present in pheno_data\n",
    "if subj_id_nb in subj_id_pheno.values:\n",
    "    # Get age of the subject in months\n",
    "    subj_age_in_month = np.array(mat_nb.get('nback_fmri_power264')[0][subj_count][0][0][0][1])\n",
    "    print(\"subj_age_in_month\", subj_age_in_month)\n",
    "    \n",
    "    # Extract bold signals for all 264 regions\n",
    "    bold_signals_all_regions = fmri_data[subj_count][2]\n",
    "    print(\"bold_signals_all_regions\", bold_signals_all_regions.shape)\n",
    "\n",
    "    # Compute Pearson correlation for all regions without transposing\n",
    "    correlation_matrix_all_regions = np.corrcoef(bold_signals_all_regions)\n",
    "    print(\"correlation_matrix_all_regions\", correlation_matrix_all_regions.shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d9c8cac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subnet_inds [ 12  13  14  15  16  17  18  19  20  21  22  23  24  25  26  27  28  29\n",
      "  30  31  32  33  34  35  36  37  38  39  40 254]\n"
     ]
    }
   ],
   "source": [
    "subnet_count = 1\n",
    "subnet_inds = p264_template[p264_template['subnet_inds'] == subnet_count]['Original_ROI'].values - 1\n",
    "print(\"subnet_inds\", subnet_inds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b5399ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "subnet_inds = [12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7c77e8aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(978,)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values_before_diagonal = [\n",
    "    correlation_matrix_all_regions[i, subnet_col] for subnet_col in (np.array(subnet_inds)-1) for i in range(subnet_col)\n",
    "]\n",
    "np.array(values_before_diagonal).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1fdaf5e2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUBJ_COUNT is: 0\n",
      "SUBJ_COUNT is: 1\n",
      "SUBJ_COUNT is: 2\n",
      "SUBJ_COUNT is: 3\n",
      "SUBJ_COUNT is: 4\n",
      "SUBJ_COUNT is: 5\n",
      "SUBJ_COUNT is: 6\n",
      "SUBJ_COUNT is: 7\n",
      "SUBJ_COUNT is: 8\n",
      "SUBJ_COUNT is: 9\n",
      "SUBJ_COUNT is: 10\n",
      "SUBJ_COUNT is: 11\n",
      "SUBJ_COUNT is: 12\n",
      "SUBJ_COUNT is: 13\n",
      "SUBJ_COUNT is: 14\n",
      "SUBJ_COUNT is: 15\n",
      "SUBJ_COUNT is: 16\n",
      "SUBJ_COUNT is: 17\n",
      "SUBJ_COUNT is: 18\n",
      "SUBJ_COUNT is: 19\n",
      "SUBJ_COUNT is: 20\n",
      "SUBJ_COUNT is: 21\n",
      "SUBJ_COUNT is: 22\n",
      "SUBJ_COUNT is: 23\n",
      "SUBJ_COUNT is: 24\n",
      "SUBJ_COUNT is: 25\n",
      "SUBJ_COUNT is: 26\n",
      "SUBJ_COUNT is: 27\n",
      "SUBJ_COUNT is: 28\n",
      "SUBJ_COUNT is: 29\n",
      "SUBJ_COUNT is: 30\n",
      "SUBJ_COUNT is: 31\n",
      "SUBJ_COUNT is: 32\n",
      "SUBJ_COUNT is: 33\n",
      "SUBJ_COUNT is: 34\n",
      "SUBJ_COUNT is: 35\n",
      "SUBJ_COUNT is: 36\n",
      "SUBJ_COUNT is: 37\n",
      "SUBJ_COUNT is: 38\n",
      "SUBJ_COUNT is: 39\n",
      "SUBJ_COUNT is: 40\n",
      "SUBJ_COUNT is: 41\n",
      "SUBJ_COUNT is: 42\n",
      "SUBJ_COUNT is: 43\n",
      "SUBJ_COUNT is: 44\n",
      "SUBJ_COUNT is: 45\n",
      "SUBJ_COUNT is: 46\n",
      "SUBJ_COUNT is: 47\n",
      "SUBJ_COUNT is: 48\n",
      "SUBJ_COUNT is: 49\n",
      "SUBJ_COUNT is: 50\n",
      "SUBJ_COUNT is: 51\n",
      "SUBJ_COUNT is: 52\n",
      "SUBJ_COUNT is: 53\n",
      "SUBJ_COUNT is: 54\n",
      "SUBJ_COUNT is: 55\n",
      "SUBJ_COUNT is: 56\n",
      "SUBJ_COUNT is: 57\n",
      "SUBJ_COUNT is: 58\n",
      "SUBJ_COUNT is: 59\n",
      "SUBJ_COUNT is: 60\n",
      "SUBJ_COUNT is: 61\n",
      "SUBJ_COUNT is: 62\n",
      "SUBJ_COUNT is: 63\n",
      "SUBJ_COUNT is: 64\n",
      "SUBJ_COUNT is: 65\n",
      "SUBJ_COUNT is: 66\n",
      "SUBJ_COUNT is: 67\n",
      "SUBJ_COUNT is: 68\n",
      "SUBJ_COUNT is: 69\n",
      "SUBJ_COUNT is: 70\n",
      "SUBJ_COUNT is: 71\n",
      "SUBJ_COUNT is: 72\n",
      "SUBJ_COUNT is: 73\n",
      "SUBJ_COUNT is: 74\n",
      "SUBJ_COUNT is: 75\n",
      "SUBJ_COUNT is: 76\n",
      "SUBJ_COUNT is: 77\n",
      "SUBJ_COUNT is: 78\n",
      "SUBJ_COUNT is: 79\n",
      "SUBJ_COUNT is: 80\n",
      "SUBJ_COUNT is: 81\n",
      "SUBJ_COUNT is: 82\n",
      "SUBJ_COUNT is: 83\n",
      "SUBJ_COUNT is: 84\n",
      "SUBJ_COUNT is: 85\n",
      "SUBJ_COUNT is: 86\n",
      "SUBJ_COUNT is: 87\n",
      "SUBJ_COUNT is: 88\n",
      "SUBJ_COUNT is: 89\n",
      "SUBJ_COUNT is: 90\n",
      "SUBJ_COUNT is: 91\n",
      "SUBJ_COUNT is: 92\n",
      "SUBJ_COUNT is: 93\n",
      "SUBJ_COUNT is: 94\n",
      "SUBJ_COUNT is: 95\n",
      "SUBJ_COUNT is: 96\n",
      "SUBJ_COUNT is: 97\n",
      "SUBJ_COUNT is: 98\n",
      "SUBJ_COUNT is: 99\n",
      "SUBJ_COUNT is: 100\n",
      "SUBJ_COUNT is: 101\n",
      "SUBJ_COUNT is: 102\n",
      "SUBJ_COUNT is: 103\n",
      "SUBJ_COUNT is: 104\n",
      "SUBJ_COUNT is: 105\n",
      "SUBJ_COUNT is: 106\n",
      "SUBJ_COUNT is: 107\n",
      "SUBJ_COUNT is: 108\n",
      "SUBJ_COUNT is: 109\n",
      "SUBJ_COUNT is: 110\n",
      "SUBJ_COUNT is: 111\n",
      "SUBJ_COUNT is: 112\n",
      "SUBJ_COUNT is: 113\n",
      "SUBJ_COUNT is: 114\n",
      "SUBJ_COUNT is: 115\n",
      "SUBJ_COUNT is: 116\n",
      "SUBJ_COUNT is: 117\n",
      "SUBJ_COUNT is: 118\n",
      "SUBJ_COUNT is: 119\n",
      "SUBJ_COUNT is: 120\n",
      "SUBJ_COUNT is: 121\n",
      "SUBJ_COUNT is: 122\n",
      "SUBJ_COUNT is: 123\n",
      "SUBJ_COUNT is: 124\n",
      "SUBJ_COUNT is: 125\n",
      "SUBJ_COUNT is: 126\n",
      "SUBJ_COUNT is: 127\n",
      "SUBJ_COUNT is: 128\n",
      "SUBJ_COUNT is: 129\n",
      "SUBJ_COUNT is: 130\n",
      "SUBJ_COUNT is: 131\n",
      "SUBJ_COUNT is: 132\n",
      "SUBJ_COUNT is: 133\n",
      "SUBJ_COUNT is: 134\n",
      "SUBJ_COUNT is: 135\n",
      "SUBJ_COUNT is: 136\n",
      "SUBJ_COUNT is: 137\n",
      "SUBJ_COUNT is: 138\n",
      "SUBJ_COUNT is: 139\n",
      "SUBJ_COUNT is: 140\n",
      "SUBJ_COUNT is: 141\n",
      "SUBJ_COUNT is: 142\n",
      "SUBJ_COUNT is: 143\n",
      "SUBJ_COUNT is: 144\n",
      "SUBJ_COUNT is: 145\n",
      "SUBJ_COUNT is: 146\n",
      "SUBJ_COUNT is: 147\n",
      "SUBJ_COUNT is: 148\n",
      "SUBJ_COUNT is: 149\n",
      "SUBJ_COUNT is: 150\n",
      "SUBJ_COUNT is: 151\n",
      "SUBJ_COUNT is: 152\n",
      "SUBJ_COUNT is: 153\n",
      "SUBJ_COUNT is: 154\n",
      "SUBJ_COUNT is: 155\n",
      "SUBJ_COUNT is: 156\n",
      "SUBJ_COUNT is: 157\n",
      "SUBJ_COUNT is: 158\n",
      "SUBJ_COUNT is: 159\n",
      "SUBJ_COUNT is: 160\n",
      "SUBJ_COUNT is: 161\n",
      "SUBJ_COUNT is: 162\n",
      "SUBJ_COUNT is: 163\n",
      "SUBJ_COUNT is: 164\n",
      "SUBJ_COUNT is: 165\n",
      "SUBJ_COUNT is: 166\n",
      "SUBJ_COUNT is: 167\n",
      "SUBJ_COUNT is: 168\n",
      "SUBJ_COUNT is: 169\n",
      "SUBJ_COUNT is: 170\n",
      "SUBJ_COUNT is: 171\n",
      "SUBJ_COUNT is: 172\n",
      "SUBJ_COUNT is: 173\n",
      "SUBJ_COUNT is: 174\n",
      "SUBJ_COUNT is: 175\n",
      "SUBJ_COUNT is: 176\n",
      "SUBJ_COUNT is: 177\n",
      "SUBJ_COUNT is: 178\n",
      "SUBJ_COUNT is: 179\n",
      "SUBJ_COUNT is: 180\n",
      "SUBJ_COUNT is: 181\n",
      "SUBJ_COUNT is: 182\n",
      "SUBJ_COUNT is: 183\n",
      "SUBJ_COUNT is: 184\n",
      "SUBJ_COUNT is: 185\n",
      "SUBJ_COUNT is: 186\n",
      "SUBJ_COUNT is: 187\n",
      "SUBJ_COUNT is: 188\n",
      "SUBJ_COUNT is: 189\n",
      "SUBJ_COUNT is: 190\n",
      "SUBJ_COUNT is: 191\n",
      "SUBJ_COUNT is: 192\n",
      "SUBJ_COUNT is: 193\n",
      "SUBJ_COUNT is: 194\n",
      "SUBJ_COUNT is: 195\n",
      "SUBJ_COUNT is: 196\n",
      "SUBJ_COUNT is: 197\n",
      "SUBJ_COUNT is: 198\n",
      "SUBJ_COUNT is: 199\n",
      "SUBJ_COUNT is: 200\n",
      "SUBJ_COUNT is: 201\n",
      "SUBJ_COUNT is: 202\n",
      "SUBJ_COUNT is: 203\n",
      "SUBJ_COUNT is: 204\n",
      "SUBJ_COUNT is: 205\n",
      "SUBJ_COUNT is: 206\n",
      "SUBJ_COUNT is: 207\n",
      "SUBJ_COUNT is: 208\n",
      "SUBJ_COUNT is: 209\n",
      "SUBJ_COUNT is: 210\n",
      "SUBJ_COUNT is: 211\n",
      "SUBJ_COUNT is: 212\n",
      "SUBJ_COUNT is: 213\n",
      "SUBJ_COUNT is: 214\n",
      "SUBJ_COUNT is: 215\n",
      "SUBJ_COUNT is: 216\n",
      "SUBJ_COUNT is: 217\n",
      "SUBJ_COUNT is: 218\n",
      "SUBJ_COUNT is: 219\n",
      "SUBJ_COUNT is: 220\n",
      "SUBJ_COUNT is: 221\n",
      "SUBJ_COUNT is: 222\n",
      "SUBJ_COUNT is: 223\n",
      "SUBJ_COUNT is: 224\n",
      "SUBJ_COUNT is: 225\n",
      "SUBJ_COUNT is: 226\n",
      "SUBJ_COUNT is: 227\n",
      "SUBJ_COUNT is: 228\n",
      "SUBJ_COUNT is: 229\n",
      "SUBJ_COUNT is: 230\n",
      "SUBJ_COUNT is: 231\n",
      "SUBJ_COUNT is: 232\n",
      "SUBJ_COUNT is: 233\n",
      "SUBJ_COUNT is: 234\n",
      "SUBJ_COUNT is: 235\n",
      "SUBJ_COUNT is: 236\n",
      "SUBJ_COUNT is: 237\n",
      "SUBJ_COUNT is: 238\n",
      "SUBJ_COUNT is: 239\n",
      "SUBJ_COUNT is: 240\n",
      "SUBJ_COUNT is: 241\n",
      "SUBJ_COUNT is: 242\n",
      "SUBJ_COUNT is: 243\n",
      "SUBJ_COUNT is: 244\n",
      "SUBJ_COUNT is: 245\n",
      "SUBJ_COUNT is: 246\n",
      "SUBJ_COUNT is: 247\n",
      "SUBJ_COUNT is: 248\n",
      "SUBJ_COUNT is: 249\n",
      "SUBJ_COUNT is: 250\n",
      "SUBJ_COUNT is: 251\n",
      "SUBJ_COUNT is: 252\n",
      "SUBJ_COUNT is: 253\n",
      "SUBJ_COUNT is: 254\n",
      "SUBJ_COUNT is: 255\n",
      "SUBJ_COUNT is: 256\n",
      "SUBJ_COUNT is: 257\n",
      "SUBJ_COUNT is: 258\n",
      "SUBJ_COUNT is: 259\n",
      "SUBJ_COUNT is: 260\n",
      "SUBJ_COUNT is: 261\n",
      "SUBJ_COUNT is: 262\n",
      "SUBJ_COUNT is: 263\n",
      "SUBJ_COUNT is: 264\n",
      "SUBJ_COUNT is: 265\n",
      "SUBJ_COUNT is: 266\n",
      "SUBJ_COUNT is: 267\n",
      "SUBJ_COUNT is: 268\n",
      "SUBJ_COUNT is: 269\n",
      "SUBJ_COUNT is: 270\n",
      "SUBJ_COUNT is: 271\n",
      "SUBJ_COUNT is: 272\n",
      "SUBJ_COUNT is: 273\n",
      "SUBJ_COUNT is: 274\n",
      "SUBJ_COUNT is: 275\n",
      "SUBJ_COUNT is: 276\n",
      "SUBJ_COUNT is: 277\n",
      "SUBJ_COUNT is: 278\n",
      "SUBJ_COUNT is: 279\n",
      "SUBJ_COUNT is: 280\n",
      "SUBJ_COUNT is: 281\n",
      "SUBJ_COUNT is: 282\n",
      "SUBJ_COUNT is: 283\n",
      "SUBJ_COUNT is: 284\n",
      "SUBJ_COUNT is: 285\n",
      "SUBJ_COUNT is: 286\n",
      "SUBJ_COUNT is: 287\n",
      "SUBJ_COUNT is: 288\n",
      "SUBJ_COUNT is: 289\n",
      "SUBJ_COUNT is: 290\n",
      "SUBJ_COUNT is: 291\n",
      "SUBJ_COUNT is: 292\n",
      "SUBJ_COUNT is: 293\n",
      "SUBJ_COUNT is: 294\n",
      "SUBJ_COUNT is: 295\n",
      "SUBJ_COUNT is: 296\n",
      "SUBJ_COUNT is: 297\n",
      "SUBJ_COUNT is: 298\n",
      "SUBJ_COUNT is: 299\n",
      "SUBJ_COUNT is: 300\n",
      "SUBJ_COUNT is: 301\n",
      "SUBJ_COUNT is: 302\n",
      "SUBJ_COUNT is: 303\n",
      "SUBJ_COUNT is: 304\n",
      "SUBJ_COUNT is: 305\n",
      "SUBJ_COUNT is: 306\n",
      "SUBJ_COUNT is: 307\n",
      "SUBJ_COUNT is: 308\n",
      "SUBJ_COUNT is: 309\n",
      "SUBJ_COUNT is: 310\n",
      "SUBJ_COUNT is: 311\n",
      "SUBJ_COUNT is: 312\n",
      "SUBJ_COUNT is: 313\n",
      "SUBJ_COUNT is: 314\n",
      "SUBJ_COUNT is: 315\n",
      "SUBJ_COUNT is: 316\n",
      "SUBJ_COUNT is: 317\n",
      "SUBJ_COUNT is: 318\n",
      "SUBJ_COUNT is: 319\n",
      "SUBJ_COUNT is: 320\n",
      "SUBJ_COUNT is: 321\n",
      "SUBJ_COUNT is: 322\n",
      "SUBJ_COUNT is: 323\n",
      "SUBJ_COUNT is: 324\n",
      "SUBJ_COUNT is: 325\n",
      "SUBJ_COUNT is: 326\n",
      "SUBJ_COUNT is: 327\n",
      "SUBJ_COUNT is: 328\n",
      "SUBJ_COUNT is: 329\n",
      "SUBJ_COUNT is: 330\n",
      "SUBJ_COUNT is: 331\n",
      "SUBJ_COUNT is: 332\n",
      "SUBJ_COUNT is: 333\n",
      "SUBJ_COUNT is: 334\n",
      "SUBJ_COUNT is: 335\n",
      "SUBJ_COUNT is: 336\n",
      "SUBJ_COUNT is: 337\n",
      "SUBJ_COUNT is: 338\n",
      "SUBJ_COUNT is: 339\n",
      "SUBJ_COUNT is: 340\n",
      "SUBJ_COUNT is: 341\n",
      "SUBJ_COUNT is: 342\n",
      "SUBJ_COUNT is: 343\n",
      "SUBJ_COUNT is: 344\n",
      "SUBJ_COUNT is: 345\n",
      "SUBJ_COUNT is: 346\n",
      "SUBJ_COUNT is: 347\n",
      "SUBJ_COUNT is: 348\n",
      "SUBJ_COUNT is: 349\n",
      "SUBJ_COUNT is: 350\n",
      "SUBJ_COUNT is: 351\n",
      "SUBJ_COUNT is: 352\n",
      "SUBJ_COUNT is: 353\n",
      "SUBJ_COUNT is: 354\n",
      "SUBJ_COUNT is: 355\n",
      "SUBJ_COUNT is: 356\n",
      "SUBJ_COUNT is: 357\n",
      "SUBJ_COUNT is: 358\n",
      "SUBJ_COUNT is: 359\n",
      "SUBJ_COUNT is: 360\n",
      "SUBJ_COUNT is: 361\n",
      "SUBJ_COUNT is: 362\n",
      "SUBJ_COUNT is: 363\n",
      "SUBJ_COUNT is: 364\n",
      "SUBJ_COUNT is: 365\n",
      "SUBJ_COUNT is: 366\n",
      "SUBJ_COUNT is: 367\n",
      "SUBJ_COUNT is: 368\n",
      "SUBJ_COUNT is: 369\n",
      "SUBJ_COUNT is: 370\n",
      "SUBJ_COUNT is: 371\n",
      "SUBJ_COUNT is: 372\n",
      "SUBJ_COUNT is: 373\n",
      "SUBJ_COUNT is: 374\n",
      "SUBJ_COUNT is: 375\n",
      "SUBJ_COUNT is: 376\n",
      "SUBJ_COUNT is: 377\n",
      "SUBJ_COUNT is: 378\n",
      "SUBJ_COUNT is: 379\n",
      "SUBJ_COUNT is: 380\n",
      "SUBJ_COUNT is: 381\n",
      "SUBJ_COUNT is: 382\n",
      "SUBJ_COUNT is: 383\n",
      "SUBJ_COUNT is: 384\n",
      "SUBJ_COUNT is: 385\n",
      "SUBJ_COUNT is: 386\n",
      "SUBJ_COUNT is: 387\n",
      "SUBJ_COUNT is: 388\n",
      "SUBJ_COUNT is: 389\n",
      "SUBJ_COUNT is: 390\n",
      "SUBJ_COUNT is: 391\n",
      "SUBJ_COUNT is: 392\n",
      "SUBJ_COUNT is: 393\n",
      "SUBJ_COUNT is: 394\n",
      "SUBJ_COUNT is: 395\n",
      "SUBJ_COUNT is: 396\n",
      "SUBJ_COUNT is: 397\n",
      "SUBJ_COUNT is: 398\n",
      "SUBJ_COUNT is: 399\n",
      "SUBJ_COUNT is: 400\n",
      "SUBJ_COUNT is: 401\n",
      "SUBJ_COUNT is: 402\n",
      "SUBJ_COUNT is: 403\n",
      "SUBJ_COUNT is: 404\n",
      "SUBJ_COUNT is: 405\n",
      "SUBJ_COUNT is: 406\n",
      "SUBJ_COUNT is: 407\n",
      "SUBJ_COUNT is: 408\n",
      "SUBJ_COUNT is: 409\n",
      "SUBJ_COUNT is: 410\n",
      "SUBJ_COUNT is: 411\n",
      "SUBJ_COUNT is: 412\n",
      "SUBJ_COUNT is: 413\n",
      "SUBJ_COUNT is: 414\n",
      "SUBJ_COUNT is: 415\n",
      "SUBJ_COUNT is: 416\n",
      "SUBJ_COUNT is: 417\n",
      "SUBJ_COUNT is: 418\n",
      "SUBJ_COUNT is: 419\n",
      "SUBJ_COUNT is: 420\n",
      "SUBJ_COUNT is: 421\n",
      "SUBJ_COUNT is: 422\n",
      "SUBJ_COUNT is: 423\n",
      "SUBJ_COUNT is: 424\n",
      "SUBJ_COUNT is: 425\n",
      "SUBJ_COUNT is: 426\n",
      "SUBJ_COUNT is: 427\n",
      "SUBJ_COUNT is: 428\n",
      "SUBJ_COUNT is: 429\n",
      "SUBJ_COUNT is: 430\n",
      "SUBJ_COUNT is: 431\n",
      "SUBJ_COUNT is: 432\n",
      "SUBJ_COUNT is: 433\n",
      "SUBJ_COUNT is: 434\n",
      "SUBJ_COUNT is: 435\n",
      "SUBJ_COUNT is: 436\n",
      "SUBJ_COUNT is: 437\n",
      "SUBJ_COUNT is: 438\n",
      "SUBJ_COUNT is: 439\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUBJ_COUNT is: 440\n",
      "SUBJ_COUNT is: 441\n",
      "SUBJ_COUNT is: 442\n",
      "SUBJ_COUNT is: 443\n",
      "SUBJ_COUNT is: 444\n",
      "SUBJ_COUNT is: 445\n",
      "SUBJ_COUNT is: 446\n",
      "SUBJ_COUNT is: 447\n",
      "SUBJ_COUNT is: 448\n",
      "SUBJ_COUNT is: 449\n",
      "SUBJ_COUNT is: 450\n",
      "SUBJ_COUNT is: 451\n",
      "SUBJ_COUNT is: 452\n",
      "SUBJ_COUNT is: 453\n",
      "SUBJ_COUNT is: 454\n",
      "SUBJ_COUNT is: 455\n",
      "SUBJ_COUNT is: 456\n",
      "SUBJ_COUNT is: 457\n",
      "SUBJ_COUNT is: 458\n",
      "SUBJ_COUNT is: 459\n",
      "SUBJ_COUNT is: 460\n",
      "SUBJ_COUNT is: 461\n",
      "SUBJ_COUNT is: 462\n",
      "SUBJ_COUNT is: 463\n",
      "SUBJ_COUNT is: 464\n",
      "SUBJ_COUNT is: 465\n",
      "SUBJ_COUNT is: 466\n",
      "SUBJ_COUNT is: 467\n",
      "SUBJ_COUNT is: 468\n",
      "SUBJ_COUNT is: 469\n",
      "SUBJ_COUNT is: 470\n",
      "SUBJ_COUNT is: 471\n",
      "SUBJ_COUNT is: 472\n",
      "SUBJ_COUNT is: 473\n",
      "SUBJ_COUNT is: 474\n",
      "SUBJ_COUNT is: 475\n",
      "SUBJ_COUNT is: 476\n",
      "SUBJ_COUNT is: 477\n",
      "SUBJ_COUNT is: 478\n",
      "SUBJ_COUNT is: 479\n",
      "SUBJ_COUNT is: 480\n",
      "SUBJ_COUNT is: 481\n",
      "SUBJ_COUNT is: 482\n",
      "SUBJ_COUNT is: 483\n",
      "SUBJ_COUNT is: 484\n",
      "SUBJ_COUNT is: 485\n",
      "SUBJ_COUNT is: 486\n",
      "SUBJ_COUNT is: 487\n",
      "SUBJ_COUNT is: 488\n",
      "SUBJ_COUNT is: 489\n",
      "SUBJ_COUNT is: 490\n",
      "SUBJ_COUNT is: 491\n",
      "SUBJ_COUNT is: 492\n",
      "SUBJ_COUNT is: 493\n",
      "SUBJ_COUNT is: 494\n",
      "SUBJ_COUNT is: 495\n",
      "SUBJ_COUNT is: 496\n",
      "SUBJ_COUNT is: 497\n",
      "SUBJ_COUNT is: 498\n",
      "SUBJ_COUNT is: 499\n",
      "SUBJ_COUNT is: 500\n",
      "SUBJ_COUNT is: 501\n",
      "SUBJ_COUNT is: 502\n",
      "SUBJ_COUNT is: 503\n",
      "SUBJ_COUNT is: 504\n",
      "SUBJ_COUNT is: 505\n",
      "SUBJ_COUNT is: 506\n",
      "SUBJ_COUNT is: 507\n",
      "SUBJ_COUNT is: 508\n",
      "SUBJ_COUNT is: 509\n",
      "SUBJ_COUNT is: 510\n",
      "SUBJ_COUNT is: 511\n",
      "SUBJ_COUNT is: 512\n",
      "SUBJ_COUNT is: 513\n",
      "SUBJ_COUNT is: 514\n",
      "SUBJ_COUNT is: 515\n",
      "SUBJ_COUNT is: 516\n",
      "SUBJ_COUNT is: 517\n",
      "SUBJ_COUNT is: 518\n",
      "SUBJ_COUNT is: 519\n",
      "SUBJ_COUNT is: 520\n",
      "SUBJ_COUNT is: 521\n",
      "SUBJ_COUNT is: 522\n",
      "SUBJ_COUNT is: 523\n",
      "SUBJ_COUNT is: 524\n",
      "SUBJ_COUNT is: 525\n",
      "SUBJ_COUNT is: 526\n",
      "SUBJ_COUNT is: 527\n",
      "SUBJ_COUNT is: 528\n",
      "SUBJ_COUNT is: 529\n",
      "SUBJ_COUNT is: 530\n",
      "SUBJ_COUNT is: 531\n",
      "SUBJ_COUNT is: 532\n",
      "SUBJ_COUNT is: 533\n",
      "SUBJ_COUNT is: 534\n",
      "SUBJ_COUNT is: 535\n",
      "SUBJ_COUNT is: 536\n",
      "SUBJ_COUNT is: 537\n",
      "SUBJ_COUNT is: 538\n",
      "SUBJ_COUNT is: 539\n",
      "SUBJ_COUNT is: 540\n",
      "SUBJ_COUNT is: 541\n",
      "SUBJ_COUNT is: 542\n",
      "SUBJ_COUNT is: 543\n",
      "SUBJ_COUNT is: 544\n",
      "SUBJ_COUNT is: 545\n",
      "SUBJ_COUNT is: 546\n",
      "SUBJ_COUNT is: 547\n",
      "SUBJ_COUNT is: 548\n",
      "SUBJ_COUNT is: 549\n",
      "SUBJ_COUNT is: 550\n",
      "SUBJ_COUNT is: 551\n",
      "SUBJ_COUNT is: 552\n",
      "SUBJ_COUNT is: 553\n",
      "SUBJ_COUNT is: 554\n",
      "SUBJ_COUNT is: 555\n",
      "SUBJ_COUNT is: 556\n",
      "SUBJ_COUNT is: 557\n",
      "SUBJ_COUNT is: 558\n",
      "SUBJ_COUNT is: 559\n",
      "SUBJ_COUNT is: 560\n",
      "SUBJ_COUNT is: 561\n",
      "SUBJ_COUNT is: 562\n",
      "SUBJ_COUNT is: 563\n",
      "SUBJ_COUNT is: 564\n",
      "SUBJ_COUNT is: 565\n",
      "SUBJ_COUNT is: 566\n",
      "SUBJ_COUNT is: 567\n",
      "SUBJ_COUNT is: 568\n",
      "SUBJ_COUNT is: 569\n",
      "SUBJ_COUNT is: 570\n",
      "SUBJ_COUNT is: 571\n",
      "SUBJ_COUNT is: 572\n",
      "SUBJ_COUNT is: 573\n",
      "SUBJ_COUNT is: 574\n",
      "SUBJ_COUNT is: 575\n",
      "SUBJ_COUNT is: 576\n",
      "SUBJ_COUNT is: 577\n",
      "SUBJ_COUNT is: 578\n",
      "SUBJ_COUNT is: 579\n",
      "SUBJ_COUNT is: 580\n",
      "SUBJ_COUNT is: 581\n",
      "SUBJ_COUNT is: 582\n",
      "SUBJ_COUNT is: 583\n",
      "SUBJ_COUNT is: 584\n",
      "SUBJ_COUNT is: 585\n",
      "SUBJ_COUNT is: 586\n",
      "SUBJ_COUNT is: 587\n",
      "SUBJ_COUNT is: 588\n",
      "SUBJ_COUNT is: 589\n",
      "SUBJ_COUNT is: 590\n",
      "SUBJ_COUNT is: 591\n",
      "SUBJ_COUNT is: 592\n",
      "SUBJ_COUNT is: 593\n",
      "SUBJ_COUNT is: 594\n",
      "SUBJ_COUNT is: 595\n",
      "SUBJ_COUNT is: 596\n",
      "SUBJ_COUNT is: 597\n",
      "SUBJ_COUNT is: 598\n",
      "SUBJ_COUNT is: 599\n",
      "SUBJ_COUNT is: 600\n",
      "SUBJ_COUNT is: 601\n",
      "SUBJ_COUNT is: 602\n",
      "SUBJ_COUNT is: 603\n",
      "SUBJ_COUNT is: 604\n",
      "SUBJ_COUNT is: 605\n",
      "SUBJ_COUNT is: 606\n",
      "SUBJ_COUNT is: 607\n",
      "SUBJ_COUNT is: 608\n",
      "SUBJ_COUNT is: 609\n",
      "SUBJ_COUNT is: 610\n",
      "SUBJ_COUNT is: 611\n",
      "SUBJ_COUNT is: 612\n",
      "SUBJ_COUNT is: 613\n",
      "SUBJ_COUNT is: 614\n",
      "SUBJ_COUNT is: 615\n",
      "SUBJ_COUNT is: 616\n",
      "SUBJ_COUNT is: 617\n",
      "SUBJ_COUNT is: 618\n",
      "SUBJ_COUNT is: 619\n",
      "SUBJ_COUNT is: 620\n",
      "SUBJ_COUNT is: 621\n",
      "SUBJ_COUNT is: 622\n",
      "SUBJ_COUNT is: 623\n",
      "SUBJ_COUNT is: 624\n",
      "SUBJ_COUNT is: 625\n",
      "SUBJ_COUNT is: 626\n",
      "SUBJ_COUNT is: 627\n",
      "SUBJ_COUNT is: 628\n",
      "SUBJ_COUNT is: 629\n",
      "SUBJ_COUNT is: 630\n",
      "SUBJ_COUNT is: 631\n",
      "SUBJ_COUNT is: 632\n",
      "SUBJ_COUNT is: 633\n",
      "SUBJ_COUNT is: 634\n",
      "SUBJ_COUNT is: 635\n",
      "SUBJ_COUNT is: 636\n",
      "SUBJ_COUNT is: 637\n",
      "SUBJ_COUNT is: 638\n",
      "SUBJ_COUNT is: 639\n",
      "SUBJ_COUNT is: 640\n",
      "SUBJ_COUNT is: 641\n",
      "SUBJ_COUNT is: 642\n",
      "SUBJ_COUNT is: 643\n",
      "SUBJ_COUNT is: 644\n",
      "SUBJ_COUNT is: 645\n",
      "SUBJ_COUNT is: 646\n",
      "SUBJ_COUNT is: 647\n",
      "SUBJ_COUNT is: 648\n",
      "SUBJ_COUNT is: 649\n",
      "SUBJ_COUNT is: 650\n",
      "SUBJ_COUNT is: 651\n",
      "SUBJ_COUNT is: 652\n",
      "SUBJ_COUNT is: 653\n",
      "SUBJ_COUNT is: 654\n",
      "SUBJ_COUNT is: 655\n",
      "SUBJ_COUNT is: 656\n",
      "SUBJ_COUNT is: 657\n",
      "SUBJ_COUNT is: 658\n",
      "SUBJ_COUNT is: 659\n",
      "SUBJ_COUNT is: 660\n",
      "SUBJ_COUNT is: 661\n",
      "SUBJ_COUNT is: 662\n",
      "SUBJ_COUNT is: 663\n",
      "SUBJ_COUNT is: 664\n",
      "SUBJ_COUNT is: 665\n",
      "SUBJ_COUNT is: 666\n",
      "SUBJ_COUNT is: 667\n",
      "SUBJ_COUNT is: 668\n",
      "SUBJ_COUNT is: 669\n",
      "SUBJ_COUNT is: 670\n",
      "SUBJ_COUNT is: 671\n",
      "SUBJ_COUNT is: 672\n",
      "SUBJ_COUNT is: 673\n",
      "SUBJ_COUNT is: 674\n",
      "SUBJ_COUNT is: 675\n",
      "SUBJ_COUNT is: 676\n",
      "SUBJ_COUNT is: 677\n",
      "SUBJ_COUNT is: 678\n",
      "SUBJ_COUNT is: 679\n",
      "SUBJ_COUNT is: 680\n",
      "SUBJ_COUNT is: 681\n",
      "SUBJ_COUNT is: 682\n",
      "SUBJ_COUNT is: 683\n",
      "SUBJ_COUNT is: 684\n",
      "SUBJ_COUNT is: 685\n",
      "SUBJ_COUNT is: 686\n",
      "SUBJ_COUNT is: 687\n",
      "SUBJ_COUNT is: 688\n",
      "SUBJ_COUNT is: 689\n",
      "SUBJ_COUNT is: 690\n",
      "SUBJ_COUNT is: 691\n",
      "SUBJ_COUNT is: 692\n",
      "SUBJ_COUNT is: 693\n",
      "SUBJ_COUNT is: 694\n",
      "SUBJ_COUNT is: 695\n",
      "SUBJ_COUNT is: 696\n",
      "SUBJ_COUNT is: 697\n",
      "SUBJ_COUNT is: 698\n",
      "SUBJ_COUNT is: 699\n",
      "SUBJ_COUNT is: 700\n",
      "SUBJ_COUNT is: 701\n",
      "SUBJ_COUNT is: 702\n",
      "SUBJ_COUNT is: 703\n",
      "SUBJ_COUNT is: 704\n",
      "SUBJ_COUNT is: 705\n",
      "SUBJ_COUNT is: 706\n",
      "SUBJ_COUNT is: 707\n",
      "SUBJ_COUNT is: 708\n",
      "SUBJ_COUNT is: 709\n",
      "SUBJ_COUNT is: 710\n",
      "SUBJ_COUNT is: 711\n",
      "SUBJ_COUNT is: 712\n",
      "SUBJ_COUNT is: 713\n",
      "SUBJ_COUNT is: 714\n",
      "SUBJ_COUNT is: 715\n",
      "SUBJ_COUNT is: 716\n",
      "SUBJ_COUNT is: 717\n",
      "SUBJ_COUNT is: 718\n",
      "SUBJ_COUNT is: 719\n",
      "SUBJ_COUNT is: 720\n",
      "SUBJ_COUNT is: 721\n",
      "SUBJ_COUNT is: 722\n",
      "SUBJ_COUNT is: 723\n",
      "SUBJ_COUNT is: 724\n",
      "SUBJ_COUNT is: 725\n",
      "SUBJ_COUNT is: 726\n",
      "SUBJ_COUNT is: 727\n",
      "SUBJ_COUNT is: 728\n",
      "SUBJ_COUNT is: 729\n",
      "SUBJ_COUNT is: 730\n",
      "SUBJ_COUNT is: 731\n",
      "SUBJ_COUNT is: 732\n",
      "SUBJ_COUNT is: 733\n",
      "SUBJ_COUNT is: 734\n",
      "SUBJ_COUNT is: 735\n",
      "SUBJ_COUNT is: 736\n",
      "SUBJ_COUNT is: 737\n",
      "SUBJ_COUNT is: 738\n",
      "SUBJ_COUNT is: 739\n",
      "SUBJ_COUNT is: 740\n",
      "SUBJ_COUNT is: 741\n",
      "SUBJ_COUNT is: 742\n",
      "SUBJ_COUNT is: 743\n",
      "SUBJ_COUNT is: 744\n",
      "SUBJ_COUNT is: 745\n",
      "SUBJ_COUNT is: 746\n",
      "SUBJ_COUNT is: 747\n",
      "SUBJ_COUNT is: 748\n",
      "SUBJ_COUNT is: 749\n",
      "SUBJ_COUNT is: 750\n",
      "SUBJ_COUNT is: 751\n",
      "SUBJ_COUNT is: 752\n",
      "SUBJ_COUNT is: 753\n",
      "SUBJ_COUNT is: 754\n",
      "SUBJ_COUNT is: 755\n",
      "SUBJ_COUNT is: 756\n",
      "SUBJ_COUNT is: 757\n",
      "SUBJ_COUNT is: 758\n",
      "SUBJ_COUNT is: 759\n",
      "SUBJ_COUNT is: 760\n",
      "SUBJ_COUNT is: 761\n",
      "SUBJ_COUNT is: 762\n",
      "SUBJ_COUNT is: 763\n",
      "SUBJ_COUNT is: 764\n",
      "SUBJ_COUNT is: 765\n",
      "SUBJ_COUNT is: 766\n",
      "SUBJ_COUNT is: 767\n",
      "SUBJ_COUNT is: 768\n",
      "SUBJ_COUNT is: 769\n",
      "SUBJ_COUNT is: 770\n",
      "SUBJ_COUNT is: 771\n",
      "SUBJ_COUNT is: 772\n",
      "SUBJ_COUNT is: 773\n",
      "SUBJ_COUNT is: 774\n",
      "SUBJ_COUNT is: 775\n",
      "SUBJ_COUNT is: 776\n",
      "SUBJ_COUNT is: 777\n",
      "SUBJ_COUNT is: 778\n",
      "SUBJ_COUNT is: 779\n",
      "SUBJ_COUNT is: 780\n",
      "SUBJ_COUNT is: 781\n",
      "SUBJ_COUNT is: 782\n",
      "SUBJ_COUNT is: 783\n",
      "SUBJ_COUNT is: 784\n",
      "SUBJ_COUNT is: 785\n",
      "SUBJ_COUNT is: 786\n",
      "SUBJ_COUNT is: 787\n",
      "SUBJ_COUNT is: 788\n",
      "SUBJ_COUNT is: 789\n",
      "SUBJ_COUNT is: 790\n",
      "SUBJ_COUNT is: 791\n",
      "SUBJ_COUNT is: 792\n",
      "SUBJ_COUNT is: 793\n",
      "SUBJ_COUNT is: 794\n",
      "SUBJ_COUNT is: 795\n",
      "SUBJ_COUNT is: 796\n",
      "SUBJ_COUNT is: 797\n",
      "SUBJ_COUNT is: 798\n",
      "SUBJ_COUNT is: 799\n",
      "SUBJ_COUNT is: 800\n",
      "SUBJ_COUNT is: 801\n",
      "SUBJ_COUNT is: 802\n",
      "SUBJ_COUNT is: 803\n",
      "SUBJ_COUNT is: 804\n",
      "SUBJ_COUNT is: 805\n",
      "SUBJ_COUNT is: 806\n",
      "SUBJ_COUNT is: 807\n",
      "SUBJ_COUNT is: 808\n",
      "SUBJ_COUNT is: 809\n",
      "SUBJ_COUNT is: 810\n",
      "SUBJ_COUNT is: 811\n",
      "SUBJ_COUNT is: 812\n",
      "SUBJ_COUNT is: 813\n",
      "SUBJ_COUNT is: 814\n",
      "SUBJ_COUNT is: 815\n",
      "SUBJ_COUNT is: 816\n",
      "SUBJ_COUNT is: 817\n",
      "SUBJ_COUNT is: 818\n",
      "SUBJ_COUNT is: 819\n",
      "SUBJ_COUNT is: 820\n",
      "SUBJ_COUNT is: 821\n",
      "SUBJ_COUNT is: 822\n",
      "SUBJ_COUNT is: 823\n",
      "SUBJ_COUNT is: 824\n",
      "SUBJ_COUNT is: 825\n",
      "SUBJ_COUNT is: 826\n",
      "SUBJ_COUNT is: 827\n",
      "SUBJ_COUNT is: 828\n",
      "SUBJ_COUNT is: 829\n",
      "SUBJ_COUNT is: 830\n",
      "SUBJ_COUNT is: 831\n",
      "SUBJ_COUNT is: 832\n",
      "SUBJ_COUNT is: 833\n",
      "SUBJ_COUNT is: 834\n",
      "SUBJ_COUNT is: 835\n",
      "SUBJ_COUNT is: 836\n",
      "SUBJ_COUNT is: 837\n",
      "SUBJ_COUNT is: 838\n",
      "SUBJ_COUNT is: 839\n",
      "SUBJ_COUNT is: 840\n",
      "SUBJ_COUNT is: 841\n",
      "SUBJ_COUNT is: 842\n",
      "SUBJ_COUNT is: 843\n",
      "SUBJ_COUNT is: 844\n",
      "SUBJ_COUNT is: 845\n",
      "SUBJ_COUNT is: 846\n",
      "SUBJ_COUNT is: 847\n",
      "SUBJ_COUNT is: 848\n",
      "SUBJ_COUNT is: 849\n",
      "SUBJ_COUNT is: 850\n",
      "SUBJ_COUNT is: 851\n",
      "SUBJ_COUNT is: 852\n",
      "SUBJ_COUNT is: 853\n",
      "SUBJ_COUNT is: 854\n",
      "SUBJ_COUNT is: 855\n",
      "SUBJ_COUNT is: 856\n",
      "SUBJ_COUNT is: 857\n",
      "SUBJ_COUNT is: 858\n",
      "SUBJ_COUNT is: 859\n",
      "SUBJ_COUNT is: 860\n",
      "SUBJ_COUNT is: 861\n",
      "SUBJ_COUNT is: 862\n",
      "SUBJ_COUNT is: 863\n",
      "SUBJ_COUNT is: 864\n",
      "SUBJ_COUNT is: 865\n",
      "SUBJ_COUNT is: 866\n",
      "SUBJ_COUNT is: 867\n",
      "SUBJ_COUNT is: 868\n",
      "SUBJ_COUNT is: 869\n",
      "SUBJ_COUNT is: 870\n",
      "SUBJ_COUNT is: 871\n",
      "SUBJ_COUNT is: 872\n",
      "SUBJ_COUNT is: 873\n",
      "SUBJ_COUNT is: 874\n",
      "SUBJ_COUNT is: 875\n",
      "SUBJ_COUNT is: 876\n",
      "SUBJ_COUNT is: 877\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUBJ_COUNT is: 878\n",
      "SUBJ_COUNT is: 879\n",
      "SUBJ_COUNT is: 880\n",
      "SUBJ_COUNT is: 881\n",
      "SUBJ_COUNT is: 882\n",
      "SUBJ_COUNT is: 883\n",
      "SUBJ_COUNT is: 884\n",
      "SUBJ_COUNT is: 885\n",
      "SUBJ_COUNT is: 886\n",
      "SUBJ_COUNT is: 887\n",
      "SUBJ_COUNT is: 888\n",
      "SUBJ_COUNT is: 889\n",
      "SUBJ_COUNT is: 890\n",
      "SUBJ_COUNT is: 891\n",
      "SUBJ_COUNT is: 892\n",
      "SUBJ_COUNT is: 893\n",
      "SUBJ_COUNT is: 894\n",
      "SUBJ_COUNT is: 895\n",
      "SUBJ_COUNT is: 896\n",
      "SUBJ_COUNT is: 897\n",
      "SUBJ_COUNT is: 898\n",
      "SUBJ_COUNT is: 899\n",
      "SUBJ_COUNT is: 900\n",
      "SUBJ_COUNT is: 901\n",
      "SUBJ_COUNT is: 902\n",
      "SUBJ_COUNT is: 903\n",
      "SUBJ_COUNT is: 904\n",
      "SUBJ_COUNT is: 905\n",
      "SUBJ_COUNT is: 906\n",
      "SUBJ_COUNT is: 907\n",
      "SUBJ_COUNT is: 908\n",
      "SUBJ_COUNT is: 909\n",
      "Shape of correlation_features_per_subnet1: (894, 1008)\n",
      "Shape of correlation_features_per_subnet2: (894, 215)\n",
      "Shape of correlation_features_per_subnet3: (894, 735)\n",
      "Shape of correlation_features_per_subnet4: (894, 858)\n",
      "Shape of correlation_features_per_subnet5: (894, 5994)\n",
      "Shape of correlation_features_per_subnet6: (894, 754)\n",
      "Shape of correlation_features_per_subnet7: (894, 4867)\n",
      "Shape of correlation_features_per_subnet8: (894, 4693)\n",
      "Shape of correlation_features_per_subnet9: (894, 3789)\n",
      "Shape of correlation_features_per_subnet10: (894, 2951)\n",
      "Shape of correlation_features_per_subnet11: (894, 2037)\n",
      "Shape of correlation_features_per_subnet12: (894, 2832)\n",
      "Shape of correlation_features_per_subnet13: (894, 974)\n",
      "Shape of correlation_features_per_subnet14: (894, 3009)\n",
      "Shape of age_in_month_subnet: (894, 1, 1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Initialize a list to store correlation features for each subnetwork\n",
    "correlation_features_per_subnet = []\n",
    "\n",
    "# Initialize lists to store correlation features for each subnet and age\n",
    "correlation_features_per_subnet = [[] for _ in range(14)]  # Initialize a list for each subnet\n",
    "age_in_month_subnet = []  # Initialize age_in_month_subnet as a list\n",
    "\n",
    "# Iterate through subjects\n",
    "for subj_count in range(len(mat_nb.get('nback_fmri_power264')[0])):\n",
    "    print(f\"SUBJ_COUNT is: {subj_count}\")\n",
    "\n",
    "    subj_id_nb = fmri_data[subj_count][0][0][0][0][0]\n",
    "\n",
    "    # Check if subject is present in pheno_data\n",
    "    if subj_id_nb in subj_id_pheno.values:\n",
    "        # Get age of the subject in months\n",
    "        subj_age_in_month = np.array(mat_nb.get('nback_fmri_power264')[0][subj_count][0][0][0][1])\n",
    "\n",
    "        # Extract bold signals for all 264 regions\n",
    "        bold_signals_all_regions = fmri_data[subj_count][2]\n",
    "\n",
    "        # Compute Pearson correlation for all regions without transposing\n",
    "        correlation_matrix_all_regions = np.corrcoef(bold_signals_all_regions)\n",
    "\n",
    "        # Iterate through subnetwork columns\n",
    "        for subnet_count in range(1, 15):\n",
    "            # Get subnet indices from p264_template\n",
    "            subnet_inds = p264_template[p264_template['subnet_inds'] == subnet_count]['Original_ROI'].values - 1\n",
    "\n",
    "            #print(f\"subj_count: {subj_count}, subnet_count: {subnet_count}, subnet_inds: {subnet_inds}\")\n",
    "\n",
    "            # Extract values before the diagonal element for the current subnet\n",
    "            values_before_diagonal = [\n",
    "                correlation_matrix_all_regions[i, subnet_col] for subnet_col in (np.array(subnet_inds)) for i in range(subnet_col)\n",
    "            ]\n",
    "\n",
    "            #print(f\"Shape of values_before_diagonal: {len(values_before_diagonal)}\")\n",
    "\n",
    "            # Append the list for the current subnet with values_before_diagonal\n",
    "            correlation_features_per_subnet[subnet_count - 1].append(values_before_diagonal)\n",
    "\n",
    "            #print(f\"Shape of correlation_features_per_subnet {subnet_count}: {np.array(correlation_features_per_subnet[subnet_count - 1]).shape}\")\n",
    "\n",
    "        # Store age in months for the current subject\n",
    "        age_in_month_subnet.append(subj_age_in_month)\n",
    "\n",
    "# Convert the lists of lists to a list of 2D NumPy arrays for further analysis\n",
    "correlation_features_per_subnet = [np.array(features) for features in correlation_features_per_subnet]\n",
    "age_in_month_subnet = np.array(age_in_month_subnet)\n",
    "\n",
    "# Print shapes\n",
    "for i, features in enumerate(correlation_features_per_subnet, start=1):\n",
    "    print(f\"Shape of correlation_features_per_subnet{i}: {features.shape}\")\n",
    "\n",
    "print(f\"Shape of age_in_month_subnet: {age_in_month_subnet.shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "75c1144d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import scipy.stats as stats\n",
    "y = np.array(age_in_month_subnet)\n",
    "ages = y[:, :, 0]\n",
    "zscores_age = stats.zscore(ages)\n",
    "#print(zscores_age)\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib import colors\n",
    "from matplotlib.ticker import PercentFormatter\n",
    "fig, ax = plt.subplots(figsize =(5, 3))\n",
    "ax.hist(zscores_age, bins = 20)\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3b97d638",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indices of excluded rows: [  0   3   4   5   6   9  10  16  18  20  22  23  26  28  33  37  38  41\n",
      "  43  44  45  47  48  49  50  56  57  59  64  67  68  73  76  77  78  79\n",
      "  82  83  86  87  89  92  94  97 100 105 109 116 117 120 121 122 125 128\n",
      " 129 131 132 136 137 139 143 144 148 151 152 154 156 158 159 166 168 171\n",
      " 173 174 181 183 184 188 191 192 201 202 204 205 206 208 209 213 217 219\n",
      " 223 225 229 230 232 235 236 238 239 242 244 245 246 247 249 250 253 255\n",
      " 256 258 262 263 264 265 270 271 275 276 281 288 290 291 293 294 295 296\n",
      " 298 299 303 306 310 312 313 314 315 319 323 324 325 327 329 330 332 340\n",
      " 343 344 346 347 350 351 357 358 360 361 362 363 367 368 369 370 371 372\n",
      " 375 376 378 379 382 387 388 389 392 394 395 398 399 406 407 408 409 410\n",
      " 411 413 416 419 420 425 427 428 432 433 436 440 443 444 449 451 455 457\n",
      " 458 460 462 463 465 466 467 469 470 474 475 476 480 482 492 497 503 506\n",
      " 507 510 512 516 517 518 524 525 528 530 535 540 542 543 553 554 559 570\n",
      " 572 573 574 578 583 585 600 604 606 607 608 609 616 618 622 623 626 631\n",
      " 632 635 637 639 640 642 645 647 648 653 656 659 669 674 675 684 687 689\n",
      " 690 691 692 694 695 696 699 700 703 704 705 706 707 708 710 711 713 714\n",
      " 716 717 718 720 725 728 729 736 737 745 746 749 750 751 752 755 760 762\n",
      " 764 772 776 777 780 787 788 789 790 791 797 798 800 803 808 809 810 815\n",
      " 818 819 821 829 831 834 836 837 838 840 846 848 851 852 853 855 858 862\n",
      " 864 865 866 868 869 871 873 874 875 879 880 881 885 886 888 889 890 892]\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats as stats\n",
    "import numpy as np\n",
    "\n",
    "# Assuming you have zscores_age and zscores defined previously\n",
    "excl_sub = 0.98\n",
    "\n",
    "# Finding indices of rows to be removed\n",
    "included_rows_indices = np.where(~((zscores_age > -excl_sub) & (zscores_age < excl_sub)))\n",
    "\n",
    "# Retrieve the indices for rows to be removed\n",
    "included_rows = excluded_rows_indices[0]\n",
    "\n",
    "# Print or use the excluded_rows as needed\n",
    "print(\"Indices of excluded rows:\", included_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "25c121cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of zscores_age_filtered: (360, 1)\n"
     ]
    }
   ],
   "source": [
    "# Assuming you already have the excluded_rows from the previous code\n",
    "\n",
    "# Use excluded_rows to keep specific rows in zscores_age\n",
    "zscores_age_filtered = zscores_age[included_rows]\n",
    "\n",
    "# Print or use zscores_age_filtered as needed\n",
    "print(\"Shape of zscores_age_filtered:\", zscores_age_filtered.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d6128683",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of correlation_features_per_subnet_filtered1: (360, 1008)\n",
      "Shape of correlation_features_per_subnet_filtered2: (360, 215)\n",
      "Shape of correlation_features_per_subnet_filtered3: (360, 735)\n",
      "Shape of correlation_features_per_subnet_filtered4: (360, 858)\n",
      "Shape of correlation_features_per_subnet_filtered5: (360, 5994)\n",
      "Shape of correlation_features_per_subnet_filtered6: (360, 754)\n",
      "Shape of correlation_features_per_subnet_filtered7: (360, 4867)\n",
      "Shape of correlation_features_per_subnet_filtered8: (360, 4693)\n",
      "Shape of correlation_features_per_subnet_filtered9: (360, 3789)\n",
      "Shape of correlation_features_per_subnet_filtered10: (360, 2951)\n",
      "Shape of correlation_features_per_subnet_filtered11: (360, 2037)\n",
      "Shape of correlation_features_per_subnet_filtered12: (360, 2832)\n",
      "Shape of correlation_features_per_subnet_filtered13: (360, 974)\n",
      "Shape of correlation_features_per_subnet_filtered14: (360, 3009)\n"
     ]
    }
   ],
   "source": [
    "# Assuming you already have the included_rows from the previous code\n",
    "\n",
    "# Use excluded_rows to keep specific rows in each list of correlation_features_per_subnet\n",
    "correlation_features_per_subnet_filtered = [\n",
    "    subnet_features[included_rows] for subnet_features in correlation_features_per_subnet\n",
    "]\n",
    "\n",
    "# Print or use correlation_features_per_subnet_filtered as needed\n",
    "for i, features in enumerate(correlation_features_per_subnet_filtered, start=1):\n",
    "    print(f\"Shape of correlation_features_per_subnet_filtered{i}: {features.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "2eb14d54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of zscores_age_thresholded: [[0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]]\n"
     ]
    }
   ],
   "source": [
    "# Assuming you already have zscores_age_filtered and excl_sub defined\n",
    "\n",
    "# Apply thresholding to zscores_age_filtered\n",
    "zscores_age_thresholded = np.where(zscores_age_filtered < -excl_sub, 0, np.where(zscores_age_filtered > excl_sub, 1, zscores_age_filtered))\n",
    "\n",
    "# Print or use zscores_age_thresholded as needed\n",
    "print(\"Shape of zscores_age_thresholded:\", zscores_age_thresholded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d972dac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_subjects: 360\n",
      "Shape of the first normalized group: (360, 1008, 1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Function to normalize a group\n",
    "def normalize_group(group):\n",
    "    min_val = np.min(group, axis=0)\n",
    "    max_val = np.max(group, axis=0)\n",
    "    normalized_group = (group - min_val) / (max_val - min_val)\n",
    "    return normalized_group\n",
    "\n",
    "\n",
    "# Extract the number of subjects\n",
    "num_subjects = correlation_features_per_subnet_filtered[0].shape[0]\n",
    "print(\"num_subjects:\", num_subjects)\n",
    "\n",
    "# Convert correlation_features_per_subnet to include a third dimension (batch_size, input_dim)\n",
    "X_subnet = [subnet.reshape((num_subjects, -1, 1)) for subnet in correlation_features_per_subnet_filtered]\n",
    "\n",
    "\n",
    "# Normalize each group and store in X_subnet_norm\n",
    "X_subnet_norm = [normalize_group(group) for group in X_subnet]\n",
    "\n",
    "# Print the shape of the first normalized group as an example\n",
    "print(\"Shape of the first normalized group:\", X_subnet_norm[0].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ea0342a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of columns from each array in X_subnet_norm: [1008, 215, 735, 858, 5994, 754, 4867, 4693, 3789, 2951, 2037, 2832, 974, 3009]\n"
     ]
    }
   ],
   "source": [
    "# Assuming you already have X_subnet_norm defined\n",
    "\n",
    "# Get the number of columns from each array in X_subnet_norm\n",
    "num_columns_list = [array.shape[1] for array in X_subnet_norm]\n",
    "\n",
    "# Print the list of numbers of columns\n",
    "print(\"Number of columns from each array in X_subnet_norm:\", num_columns_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b76aeb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "3ecc15fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_18\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_subnet_1 (InputLayer)    [(None, 1008)]       0           []                               \n",
      "                                                                                                  \n",
      " input_subnet_2 (InputLayer)    [(None, 215)]        0           []                               \n",
      "                                                                                                  \n",
      " input_subnet_3 (InputLayer)    [(None, 735)]        0           []                               \n",
      "                                                                                                  \n",
      " input_subnet_4 (InputLayer)    [(None, 858)]        0           []                               \n",
      "                                                                                                  \n",
      " input_subnet_5 (InputLayer)    [(None, 5994)]       0           []                               \n",
      "                                                                                                  \n",
      " input_subnet_6 (InputLayer)    [(None, 754)]        0           []                               \n",
      "                                                                                                  \n",
      " input_subnet_7 (InputLayer)    [(None, 4867)]       0           []                               \n",
      "                                                                                                  \n",
      " input_subnet_8 (InputLayer)    [(None, 4693)]       0           []                               \n",
      "                                                                                                  \n",
      " input_subnet_9 (InputLayer)    [(None, 3789)]       0           []                               \n",
      "                                                                                                  \n",
      " input_subnet_10 (InputLayer)   [(None, 2951)]       0           []                               \n",
      "                                                                                                  \n",
      " input_subnet_11 (InputLayer)   [(None, 2037)]       0           []                               \n",
      "                                                                                                  \n",
      " input_subnet_12 (InputLayer)   [(None, 2832)]       0           []                               \n",
      "                                                                                                  \n",
      " input_subnet_13 (InputLayer)   [(None, 974)]        0           []                               \n",
      "                                                                                                  \n",
      " input_subnet_14 (InputLayer)   [(None, 3009)]       0           []                               \n",
      "                                                                                                  \n",
      " dense_342 (Dense)              (None, 20)           20180       ['input_subnet_1[0][0]']         \n",
      "                                                                                                  \n",
      " dense_343 (Dense)              (None, 20)           4320        ['input_subnet_2[0][0]']         \n",
      "                                                                                                  \n",
      " dense_344 (Dense)              (None, 20)           14720       ['input_subnet_3[0][0]']         \n",
      "                                                                                                  \n",
      " dense_345 (Dense)              (None, 20)           17180       ['input_subnet_4[0][0]']         \n",
      "                                                                                                  \n",
      " dense_346 (Dense)              (None, 20)           119900      ['input_subnet_5[0][0]']         \n",
      "                                                                                                  \n",
      " dense_347 (Dense)              (None, 20)           15100       ['input_subnet_6[0][0]']         \n",
      "                                                                                                  \n",
      " dense_348 (Dense)              (None, 20)           97360       ['input_subnet_7[0][0]']         \n",
      "                                                                                                  \n",
      " dense_349 (Dense)              (None, 20)           93880       ['input_subnet_8[0][0]']         \n",
      "                                                                                                  \n",
      " dense_350 (Dense)              (None, 20)           75800       ['input_subnet_9[0][0]']         \n",
      "                                                                                                  \n",
      " dense_351 (Dense)              (None, 20)           59040       ['input_subnet_10[0][0]']        \n",
      "                                                                                                  \n",
      " dense_352 (Dense)              (None, 20)           40760       ['input_subnet_11[0][0]']        \n",
      "                                                                                                  \n",
      " dense_353 (Dense)              (None, 20)           56660       ['input_subnet_12[0][0]']        \n",
      "                                                                                                  \n",
      " dense_354 (Dense)              (None, 20)           19500       ['input_subnet_13[0][0]']        \n",
      "                                                                                                  \n",
      " dense_355 (Dense)              (None, 20)           60200       ['input_subnet_14[0][0]']        \n",
      "                                                                                                  \n",
      " concatenate_18 (Concatenate)   (None, 280)          0           ['dense_342[0][0]',              \n",
      "                                                                  'dense_343[0][0]',              \n",
      "                                                                  'dense_344[0][0]',              \n",
      "                                                                  'dense_345[0][0]',              \n",
      "                                                                  'dense_346[0][0]',              \n",
      "                                                                  'dense_347[0][0]',              \n",
      "                                                                  'dense_348[0][0]',              \n",
      "                                                                  'dense_349[0][0]',              \n",
      "                                                                  'dense_350[0][0]',              \n",
      "                                                                  'dense_351[0][0]',              \n",
      "                                                                  'dense_352[0][0]',              \n",
      "                                                                  'dense_353[0][0]',              \n",
      "                                                                  'dense_354[0][0]',              \n",
      "                                                                  'dense_355[0][0]']              \n",
      "                                                                                                  \n",
      " dense_356 (Dense)              (None, 32)           8992        ['concatenate_18[0][0]']         \n",
      "                                                                                                  \n",
      " dense_357 (Dense)              (None, 64)           2112        ['dense_356[0][0]']              \n",
      "                                                                                                  \n",
      " dense_358 (Dense)              (None, 128)          8320        ['dense_357[0][0]']              \n",
      "                                                                                                  \n",
      " dense_359 (Dense)              (None, 256)          33024       ['dense_358[0][0]']              \n",
      "                                                                                                  \n",
      " dense_360 (Dense)              (None, 1)            257         ['dense_359[0][0]']              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 747,305\n",
      "Trainable params: 747,305\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/50\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 2.4766 - accuracy: 0.5123 - val_loss: 2.2058 - val_accuracy: 0.5556\n",
      "Epoch 2/50\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 2.0611 - accuracy: 0.5185 - val_loss: 1.8647 - val_accuracy: 0.5556\n",
      "Epoch 3/50\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 1.7631 - accuracy: 0.5556 - val_loss: 1.5897 - val_accuracy: 0.5556\n",
      "Epoch 4/50\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 1.5042 - accuracy: 0.7222 - val_loss: 1.5438 - val_accuracy: 0.5000\n",
      "Epoch 5/50\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 1.3112 - accuracy: 0.7099 - val_loss: 1.6031 - val_accuracy: 0.5000\n",
      "Epoch 6/50\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 1.3963 - accuracy: 0.6019 - val_loss: 1.3352 - val_accuracy: 0.5833\n",
      "Epoch 7/50\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 1.2194 - accuracy: 0.7284 - val_loss: 1.4322 - val_accuracy: 0.5000\n",
      "Epoch 8/50\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 1.1280 - accuracy: 0.7253 - val_loss: 0.9950 - val_accuracy: 0.7500\n",
      "Epoch 9/50\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.9943 - accuracy: 0.7901 - val_loss: 1.0161 - val_accuracy: 0.7500\n",
      "Epoch 10/50\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.9343 - accuracy: 0.8179 - val_loss: 2.2546 - val_accuracy: 0.4444\n",
      "Epoch 11/50\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 1.3246 - accuracy: 0.5772 - val_loss: 1.1262 - val_accuracy: 0.6944\n",
      "Epoch 12/50\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 1.0074 - accuracy: 0.8148 - val_loss: 0.9383 - val_accuracy: 0.8056\n",
      "Epoch 13/50\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.9603 - accuracy: 0.8056 - val_loss: 0.9141 - val_accuracy: 0.7500\n",
      "Epoch 14/50\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.8321 - accuracy: 0.8642 - val_loss: 1.2640 - val_accuracy: 0.6944\n",
      "Epoch 15/50\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.8146 - accuracy: 0.8549 - val_loss: 1.5483 - val_accuracy: 0.6111\n",
      "Epoch 16/50\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.9130 - accuracy: 0.7778 - val_loss: 0.8658 - val_accuracy: 0.7500\n",
      "Epoch 17/50\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.7932 - accuracy: 0.8549 - val_loss: 0.7861 - val_accuracy: 0.8889\n",
      "Epoch 18/50\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.8659 - accuracy: 0.7932 - val_loss: 1.3632 - val_accuracy: 0.6667\n",
      "Epoch 19/50\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.7601 - accuracy: 0.8580 - val_loss: 0.8400 - val_accuracy: 0.7778\n",
      "Epoch 20/50\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.7316 - accuracy: 0.8673 - val_loss: 0.8049 - val_accuracy: 0.7500\n",
      "Epoch 21/50\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.5959 - accuracy: 0.9290 - val_loss: 0.6228 - val_accuracy: 0.9167\n",
      "Epoch 22/50\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.5928 - accuracy: 0.8981 - val_loss: 0.6106 - val_accuracy: 0.9167\n",
      "Epoch 23/50\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.5454 - accuracy: 0.9383 - val_loss: 0.9306 - val_accuracy: 0.7500\n",
      "Epoch 24/50\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.6452 - accuracy: 0.8858 - val_loss: 0.7301 - val_accuracy: 0.8333\n",
      "Epoch 25/50\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.6825 - accuracy: 0.8611 - val_loss: 0.6255 - val_accuracy: 0.8611\n",
      "Epoch 26/50\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.5860 - accuracy: 0.9290 - val_loss: 0.7153 - val_accuracy: 0.7778\n",
      "Epoch 27/50\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.5410 - accuracy: 0.9444 - val_loss: 0.5681 - val_accuracy: 0.9444\n",
      "Epoch 28/50\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.5108 - accuracy: 0.9383 - val_loss: 0.5363 - val_accuracy: 0.9444\n",
      "Epoch 29/50\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.5123 - accuracy: 0.9475 - val_loss: 0.7290 - val_accuracy: 0.8056\n",
      "Epoch 30/50\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.9287 - accuracy: 0.8025 - val_loss: 0.8112 - val_accuracy: 0.7500\n",
      "Epoch 31/50\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.6002 - accuracy: 0.9753 - val_loss: 0.7603 - val_accuracy: 0.7778\n",
      "Epoch 32/50\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.7020 - accuracy: 0.8827 - val_loss: 1.3045 - val_accuracy: 0.6944\n",
      "Epoch 33/50\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.6978 - accuracy: 0.8704 - val_loss: 0.8381 - val_accuracy: 0.7500\n",
      "Epoch 34/50\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.5049 - accuracy: 0.9691 - val_loss: 0.5943 - val_accuracy: 0.9444\n",
      "Epoch 35/50\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.4573 - accuracy: 0.9877 - val_loss: 0.5686 - val_accuracy: 0.9444\n",
      "Epoch 36/50\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.4266 - accuracy: 0.9877 - val_loss: 0.5632 - val_accuracy: 0.9722\n",
      "Epoch 37/50\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.4126 - accuracy: 0.9907 - val_loss: 0.7067 - val_accuracy: 0.8056\n",
      "Epoch 38/50\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.4345 - accuracy: 0.9691 - val_loss: 1.3854 - val_accuracy: 0.6944\n",
      "Epoch 39/50\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.5822 - accuracy: 0.9105 - val_loss: 1.8869 - val_accuracy: 0.6111\n",
      "Epoch 40/50\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 1.1480 - accuracy: 0.7160 - val_loss: 1.3810 - val_accuracy: 0.4444\n",
      "Epoch 41/50\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.9727 - accuracy: 0.6883 - val_loss: 0.8830 - val_accuracy: 0.8611\n",
      "Epoch 42/50\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.6888 - accuracy: 0.9691 - val_loss: 0.7689 - val_accuracy: 0.8056\n",
      "Epoch 43/50\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.5048 - accuracy: 0.9660 - val_loss: 0.9263 - val_accuracy: 0.7778\n",
      "Epoch 44/50\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.6493 - accuracy: 0.9105 - val_loss: 0.5588 - val_accuracy: 0.9444\n",
      "Epoch 45/50\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.6098 - accuracy: 0.9136 - val_loss: 0.6477 - val_accuracy: 0.8333\n",
      "Epoch 46/50\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.6697 - accuracy: 0.8920 - val_loss: 0.5906 - val_accuracy: 0.9167\n",
      "Epoch 47/50\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.5303 - accuracy: 0.9383 - val_loss: 0.8304 - val_accuracy: 0.7778\n",
      "Epoch 48/50\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.4358 - accuracy: 0.9815 - val_loss: 0.6710 - val_accuracy: 0.8056\n",
      "Epoch 49/50\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.4025 - accuracy: 0.9846 - val_loss: 0.5443 - val_accuracy: 0.9167\n",
      "Epoch 50/50\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.3922 - accuracy: 0.9846 - val_loss: 0.4913 - val_accuracy: 0.9444\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2e637451d50>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "from keras.layers import Input, Dense, Concatenate\n",
    "from keras.models import Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.regularizers import l1\n",
    "\n",
    "l1_penalty = 0.0001  # You can adjust the value based on your needs\n",
    "# Set the learning rate\n",
    "learning_rate = 0.001\n",
    "# Set the gradient clipping value\n",
    "clip_value = 0.3\n",
    "num_epochs = 50\n",
    "batch_size = 32\n",
    "\n",
    "\n",
    "# Extract the number of subjects\n",
    "num_subjects = correlation_features_per_subnet_filtered[0].shape[0]\n",
    "\n",
    "# Convert correlation_features_per_subnet to include a third dimension (batch_size, input_dim)\n",
    "X_subnet = [subnet.reshape((num_subjects, -1, 1)) for subnet in correlation_features_per_subnet_filtered]\n",
    "\n",
    "# Define the input layers for each subnet\n",
    "subnet_inputs = []\n",
    "\n",
    "num_features_list = [1008, 215, 735, 858, 5994, 754, 4867, 4693, 3789, 2951, 2037, 2832, 974, 3009]\n",
    "\n",
    "for i, num_features in enumerate(num_features_list):\n",
    "    subnet_input = Input(shape=(num_features,), name=f'input_subnet_{i + 1}')\n",
    "    subnet_inputs.append(subnet_input)\n",
    "\n",
    "# Dense layers for each subnet with L1 regularization\n",
    "subnet_dense_layers = [\n",
    "    Dense(20, activation='relu', kernel_regularizer=l1(l1_penalty))(subnet_input)\n",
    "    for subnet_input in subnet_inputs\n",
    "]\n",
    "\n",
    "# Concatenate the output of each subnet\n",
    "concatenated_layer = Concatenate()(subnet_dense_layers)\n",
    "\n",
    "# Dense layer with 32 neurons and L1 regularization\n",
    "dense_layer_32 = Dense(32, activation='relu', kernel_regularizer=l1(l1_penalty))(concatenated_layer)\n",
    "\n",
    "dense_layer_32 = Dense(64, activation='relu', kernel_regularizer=l1(l1_penalty))(dense_layer_32)\n",
    "\n",
    "# Dense layer with 128 neurons and L1 regularization\n",
    "dense_layer_32 = Dense(128, activation='relu', kernel_regularizer=l1(l1_penalty))(dense_layer_32)\n",
    "\n",
    "# Dense layer with 32 neurons\n",
    "#dense_layer_32 = Dense(256, activation='relu')(dense_layer_32)\n",
    "\n",
    "\n",
    "# Dense layer with 256 neurons and L1 regularization\n",
    "dense_layer_32 = Dense(256, activation='relu', kernel_regularizer=l1(l1_penalty))(dense_layer_32)\n",
    "\n",
    "\n",
    "# Output layer\n",
    "output_layer = Dense(units=1, activation='sigmoid')(dense_layer_32)\n",
    "\n",
    "# Create the model\n",
    "model = Model(inputs=subnet_inputs, outputs=output_layer)\n",
    "\n",
    "\n",
    "from keras.optimizers import Adam\n",
    "from keras.metrics import BinaryAccuracy\n",
    "from keras.losses import BinaryCrossentropy\n",
    "\n",
    "# Assuming you have a binary classification problem\n",
    "\n",
    "\n",
    "# Create the Adam optimizer with learning rate\n",
    "adam_optimizer = Adam(learning_rate=learning_rate) #, clipvalue=clip_value\n",
    "\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=adam_optimizer, loss='binary_crossentropy', metrics = 'accuracy')\n",
    "\n",
    "# Display the model summary\n",
    "model.summary()\n",
    "\n",
    "\n",
    "# Train the model with your data\n",
    "model.fit(X_subnet_norm, np.array(zscores_age_thresholded), epochs=num_epochs, batch_size=batch_size, validation_split=0.1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e9e371",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a3c7c9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming X_subnet_norm is a list of arrays\n",
    "X_subnet_norm_train, X_subnet_norm_val, zscores_age_thresholded_train, zscores_age_thresholded_val = [], [], [], []\n",
    "\n",
    "for subnet_data in X_subnet_norm:\n",
    "    train_data, val_data, train_labels, val_labels = train_test_split(subnet_data, np.array(zscores_age_thresholded), test_size=0.1)\n",
    "    \n",
    "    X_subnet_norm_train.append(train_data)\n",
    "    X_subnet_norm_val.append(val_data)\n",
    "    zscores_age_thresholded_train.append(train_labels)\n",
    "    zscores_age_thresholded_val.append(val_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b02b7bd",
   "metadata": {},
   "source": [
    "# Obtain feature importance scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "ab84ed22",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_13\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_subnet_1 (InputLayer)    [(None, 1008)]       0           []                               \n",
      "                                                                                                  \n",
      " input_subnet_2 (InputLayer)    [(None, 215)]        0           []                               \n",
      "                                                                                                  \n",
      " input_subnet_3 (InputLayer)    [(None, 735)]        0           []                               \n",
      "                                                                                                  \n",
      " input_subnet_4 (InputLayer)    [(None, 858)]        0           []                               \n",
      "                                                                                                  \n",
      " input_subnet_5 (InputLayer)    [(None, 5994)]       0           []                               \n",
      "                                                                                                  \n",
      " input_subnet_6 (InputLayer)    [(None, 754)]        0           []                               \n",
      "                                                                                                  \n",
      " input_subnet_7 (InputLayer)    [(None, 4867)]       0           []                               \n",
      "                                                                                                  \n",
      " input_subnet_8 (InputLayer)    [(None, 4693)]       0           []                               \n",
      "                                                                                                  \n",
      " input_subnet_9 (InputLayer)    [(None, 3789)]       0           []                               \n",
      "                                                                                                  \n",
      " input_subnet_10 (InputLayer)   [(None, 2951)]       0           []                               \n",
      "                                                                                                  \n",
      " input_subnet_11 (InputLayer)   [(None, 2037)]       0           []                               \n",
      "                                                                                                  \n",
      " input_subnet_12 (InputLayer)   [(None, 2832)]       0           []                               \n",
      "                                                                                                  \n",
      " input_subnet_13 (InputLayer)   [(None, 974)]        0           []                               \n",
      "                                                                                                  \n",
      " input_subnet_14 (InputLayer)   [(None, 3009)]       0           []                               \n",
      "                                                                                                  \n",
      " dense_247 (Dense)              (None, 10)           10090       ['input_subnet_1[0][0]']         \n",
      "                                                                                                  \n",
      " dense_248 (Dense)              (None, 10)           2160        ['input_subnet_2[0][0]']         \n",
      "                                                                                                  \n",
      " dense_249 (Dense)              (None, 10)           7360        ['input_subnet_3[0][0]']         \n",
      "                                                                                                  \n",
      " dense_250 (Dense)              (None, 10)           8590        ['input_subnet_4[0][0]']         \n",
      "                                                                                                  \n",
      " dense_251 (Dense)              (None, 10)           59950       ['input_subnet_5[0][0]']         \n",
      "                                                                                                  \n",
      " dense_252 (Dense)              (None, 10)           7550        ['input_subnet_6[0][0]']         \n",
      "                                                                                                  \n",
      " dense_253 (Dense)              (None, 10)           48680       ['input_subnet_7[0][0]']         \n",
      "                                                                                                  \n",
      " dense_254 (Dense)              (None, 10)           46940       ['input_subnet_8[0][0]']         \n",
      "                                                                                                  \n",
      " dense_255 (Dense)              (None, 10)           37900       ['input_subnet_9[0][0]']         \n",
      "                                                                                                  \n",
      " dense_256 (Dense)              (None, 10)           29520       ['input_subnet_10[0][0]']        \n",
      "                                                                                                  \n",
      " dense_257 (Dense)              (None, 10)           20380       ['input_subnet_11[0][0]']        \n",
      "                                                                                                  \n",
      " dense_258 (Dense)              (None, 10)           28330       ['input_subnet_12[0][0]']        \n",
      "                                                                                                  \n",
      " dense_259 (Dense)              (None, 10)           9750        ['input_subnet_13[0][0]']        \n",
      "                                                                                                  \n",
      " dense_260 (Dense)              (None, 10)           30100       ['input_subnet_14[0][0]']        \n",
      "                                                                                                  \n",
      " concatenate_13 (Concatenate)   (None, 140)          0           ['dense_247[0][0]',              \n",
      "                                                                  'dense_248[0][0]',              \n",
      "                                                                  'dense_249[0][0]',              \n",
      "                                                                  'dense_250[0][0]',              \n",
      "                                                                  'dense_251[0][0]',              \n",
      "                                                                  'dense_252[0][0]',              \n",
      "                                                                  'dense_253[0][0]',              \n",
      "                                                                  'dense_254[0][0]',              \n",
      "                                                                  'dense_255[0][0]',              \n",
      "                                                                  'dense_256[0][0]',              \n",
      "                                                                  'dense_257[0][0]',              \n",
      "                                                                  'dense_258[0][0]',              \n",
      "                                                                  'dense_259[0][0]',              \n",
      "                                                                  'dense_260[0][0]']              \n",
      "                                                                                                  \n",
      " dense_261 (Dense)              (None, 32)           4512        ['concatenate_13[0][0]']         \n",
      "                                                                                                  \n",
      " dense_262 (Dense)              (None, 64)           2112        ['dense_261[0][0]']              \n",
      "                                                                                                  \n",
      " dense_263 (Dense)              (None, 128)          8320        ['dense_262[0][0]']              \n",
      "                                                                                                  \n",
      " dense_264 (Dense)              (None, 256)          33024       ['dense_263[0][0]']              \n",
      "                                                                                                  \n",
      " dense_265 (Dense)              (None, 1)            257         ['dense_264[0][0]']              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 395,525\n",
      "Trainable params: 395,525\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/50\n",
      "3/3 [==============================] - 4s 394ms/step - loss: 0.9343 - accuracy: 0.4753 - val_loss: 0.7897 - val_accuracy: 0.5278\n",
      "Epoch 2/50\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 0.8349 - accuracy: 0.5185 - val_loss: 0.7198 - val_accuracy: 0.6667\n",
      "Epoch 3/50\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 0.7575 - accuracy: 0.6235 - val_loss: 0.7017 - val_accuracy: 0.8056\n",
      "Epoch 4/50\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 0.7253 - accuracy: 0.6975 - val_loss: 0.6352 - val_accuracy: 0.6667\n",
      "Epoch 5/50\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.6973 - accuracy: 0.6759 - val_loss: 0.6483 - val_accuracy: 0.8056\n",
      "Epoch 6/50\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.6424 - accuracy: 0.7130 - val_loss: 0.5939 - val_accuracy: 0.7778\n",
      "Epoch 7/50\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.5750 - accuracy: 0.7654 - val_loss: 0.5857 - val_accuracy: 0.8333\n",
      "Epoch 8/50\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 0.5265 - accuracy: 0.8148 - val_loss: 0.8438 - val_accuracy: 0.6389\n",
      "Epoch 9/50\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 0.5346 - accuracy: 0.7901 - val_loss: 0.5297 - val_accuracy: 0.8056\n",
      "Epoch 10/50\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 0.5030 - accuracy: 0.8210 - val_loss: 0.7978 - val_accuracy: 0.6944\n",
      "Epoch 11/50\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 0.4546 - accuracy: 0.8488 - val_loss: 0.4818 - val_accuracy: 0.8611\n",
      "Epoch 12/50\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 0.4563 - accuracy: 0.8549 - val_loss: 0.6866 - val_accuracy: 0.7222\n",
      "Epoch 13/50\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 0.4492 - accuracy: 0.8457 - val_loss: 0.3600 - val_accuracy: 0.9167\n",
      "Epoch 14/50\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 0.3425 - accuracy: 0.9074 - val_loss: 0.3807 - val_accuracy: 0.8333\n",
      "Epoch 15/50\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 0.2949 - accuracy: 0.9475 - val_loss: 0.3082 - val_accuracy: 0.9167\n",
      "Epoch 16/50\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.2812 - accuracy: 0.9414 - val_loss: 0.3231 - val_accuracy: 0.8889\n",
      "Epoch 17/50\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.2275 - accuracy: 0.9599 - val_loss: 0.2691 - val_accuracy: 0.9167\n",
      "Epoch 18/50\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.2046 - accuracy: 0.9691 - val_loss: 0.3747 - val_accuracy: 0.8333\n",
      "Epoch 19/50\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.2035 - accuracy: 0.9660 - val_loss: 0.2208 - val_accuracy: 0.9722\n",
      "Epoch 20/50\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 0.1907 - accuracy: 0.9691 - val_loss: 0.2138 - val_accuracy: 0.9444\n",
      "Epoch 21/50\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 0.2034 - accuracy: 0.9691 - val_loss: 0.5302 - val_accuracy: 0.8056\n",
      "Epoch 22/50\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.1773 - accuracy: 0.9753 - val_loss: 0.2667 - val_accuracy: 0.9444\n",
      "Epoch 23/50\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.1891 - accuracy: 0.9691 - val_loss: 0.8645 - val_accuracy: 0.6944\n",
      "Epoch 24/50\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 0.3555 - accuracy: 0.9043 - val_loss: 0.2121 - val_accuracy: 0.9444\n",
      "Epoch 25/50\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 0.2182 - accuracy: 0.9506 - val_loss: 0.2564 - val_accuracy: 0.9444\n",
      "Epoch 26/50\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.2148 - accuracy: 0.9599 - val_loss: 0.1806 - val_accuracy: 0.9444\n",
      "Epoch 27/50\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 0.1796 - accuracy: 0.9722 - val_loss: 0.3303 - val_accuracy: 0.9167\n",
      "Epoch 28/50\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 0.1402 - accuracy: 0.9907 - val_loss: 0.2734 - val_accuracy: 0.9444\n",
      "Epoch 29/50\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 0.1871 - accuracy: 0.9691 - val_loss: 0.6033 - val_accuracy: 0.7500\n",
      "Epoch 30/50\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 0.1725 - accuracy: 0.9722 - val_loss: 0.1955 - val_accuracy: 0.9722\n",
      "Epoch 31/50\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.1383 - accuracy: 0.9969 - val_loss: 0.1830 - val_accuracy: 0.9444\n",
      "Epoch 32/50\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.1274 - accuracy: 0.9969 - val_loss: 0.3904 - val_accuracy: 0.8889\n",
      "Epoch 33/50\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 0.1372 - accuracy: 0.9969 - val_loss: 0.1924 - val_accuracy: 0.9722\n",
      "Epoch 34/50\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 0.1205 - accuracy: 0.9969 - val_loss: 0.1605 - val_accuracy: 0.9722\n",
      "Epoch 35/50\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 0.1161 - accuracy: 1.0000 - val_loss: 0.2086 - val_accuracy: 0.9722\n",
      "Epoch 36/50\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.1143 - accuracy: 1.0000 - val_loss: 0.2741 - val_accuracy: 0.9444\n",
      "Epoch 37/50\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 0.1133 - accuracy: 1.0000 - val_loss: 0.1732 - val_accuracy: 0.9722\n",
      "Epoch 38/50\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 0.1099 - accuracy: 1.0000 - val_loss: 0.1501 - val_accuracy: 1.0000\n",
      "Epoch 39/50\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 0.1113 - accuracy: 1.0000 - val_loss: 0.1496 - val_accuracy: 1.0000\n",
      "Epoch 40/50\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.1100 - accuracy: 1.0000 - val_loss: 0.1642 - val_accuracy: 0.9722\n",
      "Epoch 41/50\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 0.1086 - accuracy: 1.0000 - val_loss: 0.2007 - val_accuracy: 0.9722\n",
      "Epoch 42/50\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 0.1086 - accuracy: 1.0000 - val_loss: 0.2231 - val_accuracy: 0.9722\n",
      "Epoch 43/50\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 0.1085 - accuracy: 1.0000 - val_loss: 0.2107 - val_accuracy: 0.9722\n",
      "Epoch 44/50\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 0.1079 - accuracy: 1.0000 - val_loss: 0.1890 - val_accuracy: 0.9722\n",
      "Epoch 45/50\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 0.1074 - accuracy: 1.0000 - val_loss: 0.1699 - val_accuracy: 0.9722\n",
      "Epoch 46/50\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.1071 - accuracy: 1.0000 - val_loss: 0.1602 - val_accuracy: 0.9722\n",
      "Epoch 47/50\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 0.1069 - accuracy: 1.0000 - val_loss: 0.1574 - val_accuracy: 0.9722\n",
      "Epoch 48/50\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 0.1066 - accuracy: 1.0000 - val_loss: 0.1591 - val_accuracy: 0.9722\n",
      "Epoch 49/50\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 0.1063 - accuracy: 1.0000 - val_loss: 0.1641 - val_accuracy: 0.9722\n",
      "Epoch 50/50\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.1061 - accuracy: 1.0000 - val_loss: 0.1698 - val_accuracy: 0.9722\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.1123 - accuracy: 0.9972\n",
      "Epoch 1/50\n",
      "12/12 [==============================] - 0s 5ms/steps: 0.1059 - accuracy: 1.\n",
      "3/3 [==============================] - 2s 963ms/step - loss: 0.1058 - accuracy: 1.0000 - val_loss: 0.1750 - val_accuracy: 0.9722\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 0s 7ms/steps: 0.1056 - accuracy: 1.\n",
      "3/3 [==============================] - 2s 866ms/step - loss: 0.1056 - accuracy: 1.0000 - val_loss: 0.1774 - val_accuracy: 0.9722\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 0s 5ms/steps: 0.1053 - accuracy: 1.\n",
      "3/3 [==============================] - 2s 813ms/step - loss: 0.1053 - accuracy: 1.0000 - val_loss: 0.1771 - val_accuracy: 0.9722\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 0s 7ms/steps: 0.1051 - accuracy: 1.\n",
      "3/3 [==============================] - 2s 806ms/step - loss: 0.1051 - accuracy: 1.0000 - val_loss: 0.1744 - val_accuracy: 0.9722\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/50\n",
      "12/12 [==============================] - 0s 7ms/steps: 0.1048 - accuracy: 1.\n",
      "3/3 [==============================] - 2s 809ms/step - loss: 0.1048 - accuracy: 1.0000 - val_loss: 0.1704 - val_accuracy: 0.9722\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 0s 6ms/steps: 0.1046 - accuracy: 1.\n",
      "3/3 [==============================] - 2s 819ms/step - loss: 0.1046 - accuracy: 1.0000 - val_loss: 0.1663 - val_accuracy: 0.9722\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 0s 7ms/steps: 0.1043 - accuracy: 1.\n",
      "3/3 [==============================] - 2s 865ms/step - loss: 0.1043 - accuracy: 1.0000 - val_loss: 0.1637 - val_accuracy: 0.9722\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 0s 8ms/steps: 0.1041 - accuracy: 1.\n",
      "3/3 [==============================] - 2s 887ms/step - loss: 0.1041 - accuracy: 1.0000 - val_loss: 0.1619 - val_accuracy: 0.9722\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 0s 8ms/steps: 0.1039 - accuracy: 1.\n",
      "3/3 [==============================] - 2s 907ms/step - loss: 0.1039 - accuracy: 1.0000 - val_loss: 0.1610 - val_accuracy: 0.9722\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 0s 6ms/steps: 0.1036 - accuracy: 1.\n",
      "3/3 [==============================] - 2s 841ms/step - loss: 0.1036 - accuracy: 1.0000 - val_loss: 0.1610 - val_accuracy: 0.9722\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - 0s 8ms/steps: 0.1034 - accuracy: 1.\n",
      "3/3 [==============================] - 2s 852ms/step - loss: 0.1034 - accuracy: 1.0000 - val_loss: 0.1626 - val_accuracy: 0.9722\n",
      "Epoch 12/50\n",
      "12/12 [==============================] - 0s 5ms/steps: 0.1032 - accuracy: 1.\n",
      "3/3 [==============================] - 2s 899ms/step - loss: 0.1032 - accuracy: 1.0000 - val_loss: 0.1639 - val_accuracy: 0.9722\n",
      "Epoch 13/50\n",
      "12/12 [==============================] - 0s 6ms/steps: 0.1029 - accuracy: 1.\n",
      "3/3 [==============================] - 2s 853ms/step - loss: 0.1029 - accuracy: 1.0000 - val_loss: 0.1648 - val_accuracy: 0.9722\n",
      "Epoch 14/50\n",
      "12/12 [==============================] - 0s 6ms/steps: 0.1027 - accuracy: 1.\n",
      "3/3 [==============================] - 2s 848ms/step - loss: 0.1027 - accuracy: 1.0000 - val_loss: 0.1647 - val_accuracy: 0.9722\n",
      "Epoch 15/50\n",
      "12/12 [==============================] - 0s 5ms/steps: 0.1025 - accuracy: 1.\n",
      "3/3 [==============================] - 2s 876ms/step - loss: 0.1025 - accuracy: 1.0000 - val_loss: 0.1640 - val_accuracy: 0.9722\n",
      "Epoch 16/50\n",
      "12/12 [==============================] - 0s 7ms/steps: 0.1022 - accuracy: 1.\n",
      "3/3 [==============================] - 2s 894ms/step - loss: 0.1022 - accuracy: 1.0000 - val_loss: 0.1629 - val_accuracy: 0.9722\n",
      "Epoch 17/50\n",
      "12/12 [==============================] - 0s 6ms/steps: 0.1020 - accuracy: 1.\n",
      "3/3 [==============================] - 2s 887ms/step - loss: 0.1020 - accuracy: 1.0000 - val_loss: 0.1623 - val_accuracy: 0.9722\n",
      "Epoch 18/50\n",
      "12/12 [==============================] - 0s 7ms/steps: 0.1018 - accuracy: 1.\n",
      "3/3 [==============================] - 2s 857ms/step - loss: 0.1018 - accuracy: 1.0000 - val_loss: 0.1612 - val_accuracy: 0.9722\n",
      "Epoch 19/50\n",
      "12/12 [==============================] - 0s 6ms/steps: 0.1016 - accuracy: 1.\n",
      "3/3 [==============================] - 2s 884ms/step - loss: 0.1016 - accuracy: 1.0000 - val_loss: 0.1603 - val_accuracy: 0.9722\n",
      "Epoch 20/50\n",
      "12/12 [==============================] - 0s 7ms/steps: 0.1013 - accuracy: 1.\n",
      "3/3 [==============================] - 2s 894ms/step - loss: 0.1013 - accuracy: 1.0000 - val_loss: 0.1604 - val_accuracy: 0.9722\n",
      "Epoch 21/50\n",
      "12/12 [==============================] - 0s 7ms/steps: 0.1011 - accuracy: 1.\n",
      "3/3 [==============================] - 2s 867ms/step - loss: 0.1011 - accuracy: 1.0000 - val_loss: 0.1605 - val_accuracy: 0.9722\n",
      "Epoch 22/50\n",
      "12/12 [==============================] - 0s 7ms/steps: 0.1009 - accuracy: 1.\n",
      "3/3 [==============================] - 2s 866ms/step - loss: 0.1009 - accuracy: 1.0000 - val_loss: 0.1609 - val_accuracy: 0.9722\n",
      "Epoch 23/50\n",
      "12/12 [==============================] - 0s 6ms/steps: 0.1007 - accuracy: 1.\n",
      "3/3 [==============================] - 2s 859ms/step - loss: 0.1007 - accuracy: 1.0000 - val_loss: 0.1613 - val_accuracy: 0.9722\n",
      "Epoch 24/50\n",
      "12/12 [==============================] - 0s 7ms/steps: 0.1004 - accuracy: 1.\n",
      "3/3 [==============================] - 2s 870ms/step - loss: 0.1004 - accuracy: 1.0000 - val_loss: 0.1618 - val_accuracy: 0.9722\n",
      "Epoch 25/50\n",
      "12/12 [==============================] - 0s 9ms/steps: 0.1002 - accuracy: 1.\n",
      "3/3 [==============================] - 2s 929ms/step - loss: 0.1002 - accuracy: 1.0000 - val_loss: 0.1609 - val_accuracy: 0.9722\n",
      "Epoch 26/50\n",
      "12/12 [==============================] - 0s 8ms/steps: 0.1000 - accuracy: 1.\n",
      "3/3 [==============================] - 2s 1s/step - loss: 0.1000 - accuracy: 1.0000 - val_loss: 0.1598 - val_accuracy: 0.9722\n",
      "Epoch 27/50\n",
      "12/12 [==============================] - 0s 6ms/steps: 0.0998 - accuracy: 1.\n",
      "3/3 [==============================] - 2s 922ms/step - loss: 0.0998 - accuracy: 1.0000 - val_loss: 0.1581 - val_accuracy: 0.9722\n",
      "Epoch 28/50\n",
      "12/12 [==============================] - 0s 6ms/steps: 0.0996 - accuracy: 1.\n",
      "3/3 [==============================] - 2s 874ms/step - loss: 0.0996 - accuracy: 1.0000 - val_loss: 0.1575 - val_accuracy: 0.9722\n",
      "Epoch 29/50\n",
      "12/12 [==============================] - 0s 7ms/steps: 0.0994 - accuracy: 1.\n",
      "3/3 [==============================] - 2s 894ms/step - loss: 0.0994 - accuracy: 1.0000 - val_loss: 0.1571 - val_accuracy: 0.9722\n",
      "Epoch 30/50\n",
      "12/12 [==============================] - 0s 6ms/steps: 0.0991 - accuracy: 1.\n",
      "3/3 [==============================] - 2s 862ms/step - loss: 0.0991 - accuracy: 1.0000 - val_loss: 0.1569 - val_accuracy: 0.9722\n",
      "Epoch 31/50\n",
      "12/12 [==============================] - 0s 7ms/steps: 0.0990 - accuracy: 1.\n",
      "3/3 [==============================] - 2s 877ms/step - loss: 0.0989 - accuracy: 1.0000 - val_loss: 0.1571 - val_accuracy: 0.9722\n",
      "Epoch 32/50\n",
      "12/12 [==============================] - 0s 6ms/steps: 0.0987 - accuracy: 1.\n",
      "3/3 [==============================] - 2s 920ms/step - loss: 0.0987 - accuracy: 1.0000 - val_loss: 0.1574 - val_accuracy: 0.9722\n",
      "Epoch 33/50\n",
      "12/12 [==============================] - 0s 7ms/steps: 0.0985 - accuracy: 1.\n",
      "3/3 [==============================] - 2s 911ms/step - loss: 0.0985 - accuracy: 1.0000 - val_loss: 0.1574 - val_accuracy: 0.9722\n",
      "Epoch 34/50\n",
      "12/12 [==============================] - 0s 6ms/steps: 0.0984 - accuracy: 1.\n",
      "3/3 [==============================] - 2s 919ms/step - loss: 0.0983 - accuracy: 1.0000 - val_loss: 0.1577 - val_accuracy: 0.9722\n",
      "Epoch 35/50\n",
      "12/12 [==============================] - 0s 6ms/steps: 0.0981 - accuracy: 1.\n",
      "3/3 [==============================] - 2s 925ms/step - loss: 0.0981 - accuracy: 1.0000 - val_loss: 0.1578 - val_accuracy: 0.9722\n",
      "Epoch 36/50\n",
      "12/12 [==============================] - 0s 8ms/steps: 0.0979 - accuracy: 1.\n",
      "3/3 [==============================] - 2s 937ms/step - loss: 0.0979 - accuracy: 1.0000 - val_loss: 0.1583 - val_accuracy: 0.9722\n",
      "Epoch 37/50\n",
      "12/12 [==============================] - 0s 8ms/steps: 0.0977 - accuracy: 1.\n",
      "3/3 [==============================] - 2s 930ms/step - loss: 0.0977 - accuracy: 1.0000 - val_loss: 0.1581 - val_accuracy: 0.9722\n",
      "Epoch 38/50\n",
      "12/12 [==============================] - 0s 7ms/steps: 0.0976 - accuracy: 1.\n",
      "3/3 [==============================] - 2s 928ms/step - loss: 0.0975 - accuracy: 1.0000 - val_loss: 0.1577 - val_accuracy: 0.9722\n",
      "Epoch 39/50\n",
      "12/12 [==============================] - 0s 6ms/steps: 0.0972 - accuracy: 1.\n",
      "3/3 [==============================] - 2s 893ms/step - loss: 0.0972 - accuracy: 1.0000 - val_loss: 0.1568 - val_accuracy: 0.9722\n",
      "Epoch 40/50\n",
      "12/12 [==============================] - 0s 6ms/steps: 0.0970 - accuracy: 1.\n",
      "3/3 [==============================] - 2s 991ms/step - loss: 0.0970 - accuracy: 1.0000 - val_loss: 0.1559 - val_accuracy: 0.9722\n",
      "Epoch 41/50\n",
      "12/12 [==============================] - 0s 8ms/steps: 0.0968 - accuracy: 1.\n",
      "3/3 [==============================] - 2s 941ms/step - loss: 0.0968 - accuracy: 1.0000 - val_loss: 0.1556 - val_accuracy: 0.9722\n",
      "Epoch 42/50\n",
      "12/12 [==============================] - 0s 7ms/steps: 0.0966 - accuracy: 1.\n",
      "3/3 [==============================] - 2s 914ms/step - loss: 0.0966 - accuracy: 1.0000 - val_loss: 0.1548 - val_accuracy: 0.9722\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/50\n",
      "12/12 [==============================] - 0s 7ms/steps: 0.0964 - accuracy: 1.\n",
      "3/3 [==============================] - 2s 943ms/step - loss: 0.0964 - accuracy: 1.0000 - val_loss: 0.1547 - val_accuracy: 0.9722\n",
      "Epoch 44/50\n",
      "12/12 [==============================] - 0s 7ms/steps: 0.0962 - accuracy: 1.\n",
      "3/3 [==============================] - 2s 961ms/step - loss: 0.0962 - accuracy: 1.0000 - val_loss: 0.1542 - val_accuracy: 0.9722\n",
      "Epoch 45/50\n",
      "12/12 [==============================] - 0s 6ms/steps: 0.0961 - accuracy: 1.\n",
      "3/3 [==============================] - 2s 909ms/step - loss: 0.0960 - accuracy: 1.0000 - val_loss: 0.1538 - val_accuracy: 0.9722\n",
      "Epoch 46/50\n",
      "12/12 [==============================] - 0s 5ms/steps: 0.0959 - accuracy: 1.\n",
      "3/3 [==============================] - 2s 796ms/step - loss: 0.0958 - accuracy: 1.0000 - val_loss: 0.1538 - val_accuracy: 0.9722\n",
      "Epoch 47/50\n",
      "12/12 [==============================] - 0s 5ms/steps: 0.0956 - accuracy: 1.\n",
      "3/3 [==============================] - 2s 758ms/step - loss: 0.0956 - accuracy: 1.0000 - val_loss: 0.1535 - val_accuracy: 0.9722\n",
      "Epoch 48/50\n",
      "12/12 [==============================] - 0s 6ms/steps: 0.0955 - accuracy: 1.\n",
      "3/3 [==============================] - 2s 865ms/step - loss: 0.0954 - accuracy: 1.0000 - val_loss: 0.1531 - val_accuracy: 0.9722\n",
      "Epoch 49/50\n",
      "12/12 [==============================] - 0s 5ms/steps: 0.0953 - accuracy: 1.00\n",
      "3/3 [==============================] - 2s 843ms/step - loss: 0.0952 - accuracy: 1.0000 - val_loss: 0.1525 - val_accuracy: 0.9722\n",
      "Epoch 50/50\n",
      "12/12 [==============================] - 0s 6ms/steps: 0.0951 - accuracy: 1.\n",
      "Gradient Shape for Last Epoch:\n",
      "Input 1: (360, 1008, 1)\n",
      "Input 2: (360, 215, 1)\n",
      "Input 3: (360, 735, 1)\n",
      "Input 4: (360, 858, 1)\n",
      "Input 5: (360, 5994, 1)\n",
      "Input 6: (360, 754, 1)\n",
      "Input 7: (360, 4867, 1)\n",
      "Input 8: (360, 4693, 1)\n",
      "Input 9: (360, 3789, 1)\n",
      "Input 10: (360, 2951, 1)\n",
      "Input 11: (360, 2037, 1)\n",
      "Input 12: (360, 2832, 1)\n",
      "Input 13: (360, 974, 1)\n",
      "Input 14: (360, 3009, 1)\n",
      "3/3 [==============================] - 2s 869ms/step - loss: 0.0950 - accuracy: 1.0000 - val_loss: 0.1524 - val_accuracy: 0.9722\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dense, Concatenate\n",
    "from keras.models import Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.regularizers import l1\n",
    "from keras.optimizers import Adam\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.callbacks import Callback\n",
    "from keras import backend as K\n",
    "\n",
    "# Assuming you have binary classification labels\n",
    "# Replace this with your actual labels\n",
    "#zscores_age_thresholded = np.random.randint(2, size=(100, 1))\n",
    "\n",
    "# Assuming you have a list of arrays as input data\n",
    "# Replace this with your actual input data\n",
    "#correlation_features_per_subnet_filtered = [np.random.rand(100, 10) for _ in range(13)]\n",
    "\n",
    "# Extract the number of subjects\n",
    "num_subjects = correlation_features_per_subnet_filtered[0].shape[0]\n",
    "\n",
    "# Convert correlation_features_per_subnet to include a third dimension (batch_size, input_dim)\n",
    "X_subnet = [subnet.reshape((num_subjects, -1, 1)) for subnet in correlation_features_per_subnet_filtered]\n",
    "\n",
    "# Define the input layers for each subnet\n",
    "subnet_inputs = []\n",
    "\n",
    "num_features_list = [1008, 215, 735, 858, 5994, 754, 4867, 4693, 3789, 2951, 2037, 2832, 974, 3009]\n",
    "\n",
    "for i, num_features in enumerate(num_features_list):\n",
    "    subnet_input = Input(shape=(num_features,), name=f'input_subnet_{i + 1}')\n",
    "    subnet_inputs.append(subnet_input)\n",
    "\n",
    "# Dense layers for each subnet with L1 regularization\n",
    "subnet_dense_layers = [\n",
    "    Dense(10, activation='elu', kernel_regularizer=l1(0.00001))(subnet_input)\n",
    "    for subnet_input in subnet_inputs\n",
    "]\n",
    "\n",
    "# Concatenate the output of each subnet\n",
    "concatenated_layer = Concatenate()(subnet_dense_layers)\n",
    "\n",
    "# Dense layer with 32 neurons and L1 regularization\n",
    "dense_layer_32 = Dense(32, activation='elu', kernel_regularizer=l1(0.00001))(concatenated_layer)\n",
    "\n",
    "dense_layer_32 = Dense(64, activation='elu', kernel_regularizer=l1(0.00001))(dense_layer_32)\n",
    "\n",
    "# Dense layer with 128 neurons and L1 regularization\n",
    "dense_layer_32 = Dense(128, activation='elu', kernel_regularizer=l1(0.00001))(dense_layer_32)\n",
    "\n",
    "# Dense layer with 256 neurons and L1 regularization\n",
    "dense_layer_32 = Dense(256, activation='elu', kernel_regularizer=l1(0.00001))(dense_layer_32)\n",
    "\n",
    "# Output layer\n",
    "output_layer = Dense(units=1, activation='sigmoid')(dense_layer_32)\n",
    "\n",
    "# Create the model\n",
    "model = Model(inputs=subnet_inputs, outputs=output_layer)\n",
    "\n",
    "# Set the learning rate\n",
    "learning_rate = 0.001\n",
    "# Set the gradient clipping value\n",
    "clip_value = 0.2\n",
    "\n",
    "# Create the Adam optimizer with learning rate\n",
    "adam_optimizer = Adam(learning_rate=learning_rate, clipvalue=clip_value)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=adam_optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Display the model summary\n",
    "model.summary()\n",
    "\n",
    "# Train the model without the callback\n",
    "model.fit(X_subnet, np.array(zscores_age_thresholded), epochs=num_epochs, batch_size=batch_size, validation_split=0.1)\n",
    "\n",
    "# Evaluate the model on the entire dataset\n",
    "model.evaluate(X_subnet, np.array(zscores_age_thresholded))\n",
    "\n",
    "class GradientCallback(Callback):\n",
    "    def __init__(self, data):\n",
    "        super(GradientCallback, self).__init__()\n",
    "        self.data = data\n",
    "        self.Feat_import = None  # Initialize Feat_import variable\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        # Check if data is available\n",
    "        if self.data is None:\n",
    "            raise ValueError(\"Data is not provided. Set data during model.fit.\")\n",
    "\n",
    "        inputs = self.data[0]\n",
    "        outputs = self.model.predict(inputs)\n",
    "\n",
    "        if not isinstance(inputs, list):\n",
    "            inputs = [inputs]\n",
    "\n",
    "        # Convert NumPy arrays to TensorFlow tensors\n",
    "        inputs = [tf.convert_to_tensor(input_array, dtype=tf.float32) for input_array in inputs]\n",
    "\n",
    "        with tf.GradientTape(persistent=True) as tape:\n",
    "            tape.watch(inputs)\n",
    "            model_output = self.model(inputs)\n",
    "\n",
    "        gradients = [tape.gradient(model_output, input_tensor) for input_tensor in inputs]\n",
    "\n",
    "        # Store the gradients in Feat_import\n",
    "        self.Feat_import = gradients\n",
    "\n",
    "        # Print the shape of the gradients for the last epoch\n",
    "        if epoch == (self.params['epochs'] - 1):  # Check if it's the last epoch\n",
    "            print(\"Gradient Shape for Last Epoch:\")\n",
    "            for i, gradient in enumerate(gradients):\n",
    "                print(f'Input {i + 1}: {gradient.shape}')\n",
    "\n",
    "                \n",
    "\n",
    "# Create an instance of the callback with the entire dataset\n",
    "gradient_callback = GradientCallback(data=(X_subnet, zscores_age_thresholded))\n",
    "\n",
    "# Train the model with the added callback and the entire dataset\n",
    "model.fit(X_subnet, np.array(zscores_age_thresholded),\n",
    "          epochs=num_epochs, batch_size=batch_size,\n",
    "          validation_split=0.1,\n",
    "          callbacks=[gradient_callback])\n",
    "\n",
    "# Access Feat_import after training\n",
    "feat_import = gradient_callback.Feat_import\n",
    "\n",
    "# Now feat_import contains gradients for the entire dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "ac726eea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1008, 1)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(feat_import[0],axis=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9c2534",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209c1a52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d520cce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a3a82d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
